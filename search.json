[
  {
    "objectID": "mlm_seminar_sose23/lineare_regression.html",
    "href": "mlm_seminar_sose23/lineare_regression.html",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Das Ziel einer Regression besteht darin, eine Variable durch eine oder mehrere andere Variablen vorherzusagen. An dieser Stelle k√∂nnen wir von einer Art Prognose sprechen. Wenn wir Regressionsmodelle benutzen, wollen wir den Verlauf einer Variable (die abh√§ngige Variable) anhand anderer Variablen (unabh√§ngige Variablen) prognostizieren.\nDie vorhergesagte Variable wird Kriterium, Regressand oder auch abh√§ngige Variable (AV) genannt und wird √ºblicherweise mit \\(y\\) symbolisiert. Die Variablen, die zur Vorhersage der abh√§ngigen Variablen verwendet werden, werden Pr√§diktoren, Regressoren oder unabh√§ngige Variablen (UV) genannt. √úblicherweise werden Pr√§diktoren mit \\(x_{1},~x_{2},~x_{3},~\\dots\\) (oder kurz, mit \\(X\\)) symbolisiert.\nSie erinnern sich wahrscheinlich an Statistik 1 und 2, wo wir meistens nur einen Pr√§diktor zur Vorhersage einer anderen Variable benutzt haben. In diesem Fall sprechen wir von einer einfachen Regression. In diesem Fall k√∂nnen wir eine Vorhersage von \\(y\\) mit der Gleichung der einfachen linearen Regression formalisieren:\n\\[\ny_{m} = b_{0} + b_{1} \\cdot x_{m1} + b_{2} \\cdot x_{m2} + \\dots + e_{m}\n\\tag{1}\\]\nHier steht der Index \\(\\mathbf{m}\\) f√ºr die Untersuchungseinheit (z.B. f√ºr eine Person, oder eine einzelne Messung).\nUm die Grundidee eines Regressionsmodells besser zu verstehen, schauen wir uns nun ein kleines Beispiel an.\n\n\n\nBetrachten Sie die folgende Abbildung:\n\n\n\nAnstieg des Meeresspiegels seit dem Jahr 1993 bis 2021 in Millimeter (Stand: September). In Statista. Zugriff am 15. Mai 2023, von https://de.statista.com/statistik/daten/studie/1056576/umfrage/hoehe-des-meeresspiegels/\n\n\n\n\n\n\n\n\nWas k√∂nnen wir aus dieser Abbildung lernen?\n\n\n\n\n\nDie Abbildung zeigt, dass der Meeresspiegel kontinuierlich ansteigt. Anhand der abgebildeten Zahlen l√§sst sich leicht erkennen, dass seit 1993 der Meeresspiegel pro Jahr um mehrere Millimeter angestiegen ist.\n\n\n\n\nGehen wir davon aus, dass wir die Ver√§nderung im Meeresspiegel, die durch die Abbildung angedeutet wird, m√∂glichst pr√§gnant zusammenfassen wollen. An dieser Stelle stehen uns unterschiedliche Methoden zur Verf√ºgung. Wir k√∂nnten sagen:\n\n\n\n‚ÄúDer Meeresspiegel ist seit 1993 gestiegen‚Äù, oder ‚ÄúDer Meeresspiegel steigt seit 1993 um mehrere Millimeter‚Äù.\n\n\n\nSobald wir aber eine Aussage √ºber die Auspr√§gung dieser Ver√§nderung treffen m√∂chten, br√§uchten wir eine Methode, die uns erlaubt all die kleinen Ver√§nderungen, welche von Jahr zu Jahr gemessen wurden, zusammenzufassen. Eine M√∂glichkeit w√§re, die gemessenen Abweichungen zu mitteln. Damit k√∂nnten wir feststellen, um wie viel der Meeresspiegel im Mittel pro Jahr angestiegen (oder abgefallen ist). Lasst uns diese Berechnung in R durchf√ºhren.\n\n\n\n\n# die Daten k√∂nnen mit diesem Befehl geladen werden\nmeeresspiegel &lt;- read.csv(file=\"https://raw.githubusercontent.com/JoseAlanis/amdstatsem/main/data/meeresspiegel.csv\")\n\n\n\n\n\n# wir k√∂nnen `dplyr` benutzen \n# um die mittlere Abweichung zu berechnen\nrequire(dplyr)\n\nmeeresspiegel %&gt;%\n  # Differenz zwischen zwei aufeinaderefolgende Werte\n  mutate(Abweichung = lead(Anstieg) - Anstieg) %&gt;%\n  # bilde Mittelwert (schlie√ü Fehlendewerte aus)\n  summarize(Mittlere_Abweichung = mean(Abweichung, na.rm = TRUE))\n\n  Mittlere_Abweichung\n1            3.607143\n\n\n\nNun k√∂nnen wir die Abweichung im Meeresspiegel genauer Beschreiben:\n\n\n\nDie Abbildung zeigt, dass der Meeresspiegel kontinuierlich ansteigt. Tats√§chlich steigt der Meeresspiegel im Vergleich zu 1993 pro Jahr um durchschnittlich 3,6 mm.\n\n\n\n\n\n\nAnhand dieser Zahlen liese sich gleich prognostizieren, wie der Meerespiegel in den komenden Jahren ver√§ndern wird. Wenn alles so bleibt wie bisher, k√∂nnen wir davon ausgehen, dass der Meeresspiegel weiteransteigen wird. Das sind keine gute Nachrichten.\nEine gute Nachricht ist allerdings, dass lineare Regressionsmodelle, im Prinzip nichts anderes als die mittlere Abweichung zu berechnen, um eine Vorhersage von \\(y\\) (in unser Beispiel die Abweichung im gemessenen Meeresspiegel) anhand von \\(x\\) (in unser Beispiel, das Jahr der Messung) vorzunehmen. Die genauen Berechnungsschritte sind ein kleines bisschen komplexer, aber die Logik ist im Prinzip die gleiche.\nWir k√∂nnen dies leicht mit einem linearen Regression in R √ºberpr√ºfen.\n\n\nWir k√∂nnen eine lineare Regression mit der Funktion lm() in R berechnen.\n\n# lm() nimmt mehrere Argumente. Heute brauchen wir `data` und `formula`\n# `data = meeresspiegel` sagt der Funktion wo sich die Daten befinden\nlin_reg &lt;- lm(\n  # `data = meeresspiegel` sagt der Funktion wo sich die Daten befinden\n  data = meeresspiegel, \n  # `formula = 1 +  Anstieg ~ Jahr` sagt der Funktion wie die Formel unserer\n  # Regression aussehen soll\n              formula = 1 +  Anstieg ~ Jahr)\n\nMit summary() k√∂nnen wir uns die Ergebnisse der Regression anzeigen lassen:\n\nsummary(lin_reg)\n\n\nCall:\nlm(formula = 1 + Anstieg ~ Jahr, data = meeresspiegel)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.4157  -2.7138   0.3881   2.3164   7.7297 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.728e+03  1.882e+02  -35.75   &lt;2e-16 ***\nJahr         3.375e+00  9.375e-02   36.00   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.224 on 27 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9788 \nF-statistic:  1296 on 1 and 27 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nWie kommen diese Zahlen zustande?\nWie k√∂nnen wir aus vergangenen Beobachtungen zuk√ºnftige Beobachtungen vorhersagen?\nWas ist eine gute Vorhersage, und warum sind Vorhersagen mehr oder weniger akkurat?\n\n\nSchauen wir uns ein weiteres Beispiel an.\n\n\n\n\n\nStellen Sie sich vor, dass Sie als ambulante Psychotherapeut:in in einer Praxis arbeiten. Am Anfang eines jeden Quartals erstellen Sie eine Kostenplanung. Die erwartete Anzahl an Behandlungsstunden spielt dabei eine gro√üe Rolle, da Sie damit den erwarteten Wert Ihres Einkommens berechnen k√∂nnen. Gehen wir davon aus, dass Sie pro Patient:in ein Betrag von 66,6 Euro (nach Abzug aller laufenden Kosten) in der Quartalsabrechnung erwarten k√∂nnen.\n\nBetrachten Sie die folgende Abbildung:\n\n\nDie Abbildung zeigt einen linearen Zusammenhang zwischen der Anzahl an Patienten und dem Betrag auf der Abrechnung. Wir k√∂nnen dieser Zusammenhang bildlich darstellen (wie in der Abbildung) aber auch mithilfe mit eines Modells.\n\n\\[Betrag = (wie~von~x~auf~y~kommen?) + Fehler\\]\n\nIn unseren Beispiel, welche Funktion muss auf \\(x\\) angewendet werden, um eine m√∂glichst genaue Sch√§tzung von \\(y\\) zu bekommen?\nWir k√∂nnen diese Fragen mithilfe einer mathematischen Formel ausdrucken.\n\n\\[y = f(x) + Fehler\\]\n\nDies ist die Grundlage eines Regressionsmodells. Regressionsmodelle sind nichts anderes als eine Speziefietzierung dieser Frage. Mit einem Regressionsmodell, k√∂nnen wir die Funktion, die auf \\(x\\) angewendet werden muss, genauer beschreiben.\nDies ist die allgemeine Formel der Regression:\n\n\\[y_{i} = b_{0} + b_{1}~x_{1} + e_{i}\\]\n\n\n\\(b_{0} =\\) \\(y\\)-Achsenabschnitt, Konstante, oder Interzept:\n\nDer Wert von \\(y\\) bei einer Auspr√§gung von 0 in \\(x\\).\n\n\\(b_{1} =\\) Regressionsgewicht des Pr√§diktors oder die Steigung der Regressionsgerade.\n\nInterpretation: die Steigung der Geraden l√§sst erkennen, um wie viele Einheiten \\(y\\) zunimmt, wenn \\(x\\) um eine Einheit zunimmt\n\n\\(e_{i} =\\) Regressionsresiduum (kurz: Residuum), Residualwert oder Fehlerwert:\n\nDie Differenz zwischen einem vorhergesagten (\\(\\hat{y}\\)) und beobachteten (\\(y\\)) \\(y\\)-Wert.\nJe gr√∂√üer die Fehlerwerte, umso gr√∂√üer ist die Abweichung eines beobachteten vom vorhergesagten Wert.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "3. Linerare Regression"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression.html#beispiel-1-der-meeresspiegel-steigt-an",
    "href": "mlm_seminar_sose23/lineare_regression.html#beispiel-1-der-meeresspiegel-steigt-an",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Betrachten Sie die folgende Abbildung:\n\n\n\nAnstieg des Meeresspiegels seit dem Jahr 1993 bis 2021 in Millimeter (Stand: September). In Statista. Zugriff am 15. Mai 2023, von https://de.statista.com/statistik/daten/studie/1056576/umfrage/hoehe-des-meeresspiegels/\n\n\n\n\n\n\n\n\nWas k√∂nnen wir aus dieser Abbildung lernen?\n\n\n\n\n\nDie Abbildung zeigt, dass der Meeresspiegel kontinuierlich ansteigt. Anhand der abgebildeten Zahlen l√§sst sich leicht erkennen, dass seit 1993 der Meeresspiegel pro Jahr um mehrere Millimeter angestiegen ist.\n\n\n\n\nGehen wir davon aus, dass wir die Ver√§nderung im Meeresspiegel, die durch die Abbildung angedeutet wird, m√∂glichst pr√§gnant zusammenfassen wollen. An dieser Stelle stehen uns unterschiedliche Methoden zur Verf√ºgung. Wir k√∂nnten sagen:\n\n\n\n‚ÄúDer Meeresspiegel ist seit 1993 gestiegen‚Äù, oder ‚ÄúDer Meeresspiegel steigt seit 1993 um mehrere Millimeter‚Äù.\n\n\n\nSobald wir aber eine Aussage √ºber die Auspr√§gung dieser Ver√§nderung treffen m√∂chten, br√§uchten wir eine Methode, die uns erlaubt all die kleinen Ver√§nderungen, welche von Jahr zu Jahr gemessen wurden, zusammenzufassen. Eine M√∂glichkeit w√§re, die gemessenen Abweichungen zu mitteln. Damit k√∂nnten wir feststellen, um wie viel der Meeresspiegel im Mittel pro Jahr angestiegen (oder abgefallen ist). Lasst uns diese Berechnung in R durchf√ºhren.\n\n\n\n\n# die Daten k√∂nnen mit diesem Befehl geladen werden\nmeeresspiegel &lt;- read.csv(file=\"https://raw.githubusercontent.com/JoseAlanis/amdstatsem/main/data/meeresspiegel.csv\")\n\n\n\n\n\n# wir k√∂nnen `dplyr` benutzen \n# um die mittlere Abweichung zu berechnen\nrequire(dplyr)\n\nmeeresspiegel %&gt;%\n  # Differenz zwischen zwei aufeinaderefolgende Werte\n  mutate(Abweichung = lead(Anstieg) - Anstieg) %&gt;%\n  # bilde Mittelwert (schlie√ü Fehlendewerte aus)\n  summarize(Mittlere_Abweichung = mean(Abweichung, na.rm = TRUE))\n\n  Mittlere_Abweichung\n1            3.607143\n\n\n\nNun k√∂nnen wir die Abweichung im Meeresspiegel genauer Beschreiben:\n\n\n\nDie Abbildung zeigt, dass der Meeresspiegel kontinuierlich ansteigt. Tats√§chlich steigt der Meeresspiegel im Vergleich zu 1993 pro Jahr um durchschnittlich 3,6 mm.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "3. Linerare Regression"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression.html#ist-die-mittlere-abweichung-ein-guter-sch√§tzer",
    "href": "mlm_seminar_sose23/lineare_regression.html#ist-die-mittlere-abweichung-ein-guter-sch√§tzer",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Anhand dieser Zahlen liese sich gleich prognostizieren, wie der Meerespiegel in den komenden Jahren ver√§ndern wird. Wenn alles so bleibt wie bisher, k√∂nnen wir davon ausgehen, dass der Meeresspiegel weiteransteigen wird. Das sind keine gute Nachrichten.\nEine gute Nachricht ist allerdings, dass lineare Regressionsmodelle, im Prinzip nichts anderes als die mittlere Abweichung zu berechnen, um eine Vorhersage von \\(y\\) (in unser Beispiel die Abweichung im gemessenen Meeresspiegel) anhand von \\(x\\) (in unser Beispiel, das Jahr der Messung) vorzunehmen. Die genauen Berechnungsschritte sind ein kleines bisschen komplexer, aber die Logik ist im Prinzip die gleiche.\nWir k√∂nnen dies leicht mit einem linearen Regression in R √ºberpr√ºfen.\n\n\nWir k√∂nnen eine lineare Regression mit der Funktion lm() in R berechnen.\n\n# lm() nimmt mehrere Argumente. Heute brauchen wir `data` und `formula`\n# `data = meeresspiegel` sagt der Funktion wo sich die Daten befinden\nlin_reg &lt;- lm(\n  # `data = meeresspiegel` sagt der Funktion wo sich die Daten befinden\n  data = meeresspiegel, \n  # `formula = 1 +  Anstieg ~ Jahr` sagt der Funktion wie die Formel unserer\n  # Regression aussehen soll\n              formula = 1 +  Anstieg ~ Jahr)\n\nMit summary() k√∂nnen wir uns die Ergebnisse der Regression anzeigen lassen:\n\nsummary(lin_reg)\n\n\nCall:\nlm(formula = 1 + Anstieg ~ Jahr, data = meeresspiegel)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.4157  -2.7138   0.3881   2.3164   7.7297 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.728e+03  1.882e+02  -35.75   &lt;2e-16 ***\nJahr         3.375e+00  9.375e-02   36.00   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.224 on 27 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9788 \nF-statistic:  1296 on 1 and 27 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nWie kommen diese Zahlen zustande?\nWie k√∂nnen wir aus vergangenen Beobachtungen zuk√ºnftige Beobachtungen vorhersagen?\nWas ist eine gute Vorhersage, und warum sind Vorhersagen mehr oder weniger akkurat?\n\n\nSchauen wir uns ein weiteres Beispiel an.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "3. Linerare Regression"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression.html#beispiel-2-more-patients-more-cash",
    "href": "mlm_seminar_sose23/lineare_regression.html#beispiel-2-more-patients-more-cash",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Stellen Sie sich vor, dass Sie als ambulante Psychotherapeut:in in einer Praxis arbeiten. Am Anfang eines jeden Quartals erstellen Sie eine Kostenplanung. Die erwartete Anzahl an Behandlungsstunden spielt dabei eine gro√üe Rolle, da Sie damit den erwarteten Wert Ihres Einkommens berechnen k√∂nnen. Gehen wir davon aus, dass Sie pro Patient:in ein Betrag von 66,6 Euro (nach Abzug aller laufenden Kosten) in der Quartalsabrechnung erwarten k√∂nnen.\n\nBetrachten Sie die folgende Abbildung:\n\n\nDie Abbildung zeigt einen linearen Zusammenhang zwischen der Anzahl an Patienten und dem Betrag auf der Abrechnung. Wir k√∂nnen dieser Zusammenhang bildlich darstellen (wie in der Abbildung) aber auch mithilfe mit eines Modells.\n\n\\[Betrag = (wie~von~x~auf~y~kommen?) + Fehler\\]\n\nIn unseren Beispiel, welche Funktion muss auf \\(x\\) angewendet werden, um eine m√∂glichst genaue Sch√§tzung von \\(y\\) zu bekommen?\nWir k√∂nnen diese Fragen mithilfe einer mathematischen Formel ausdrucken.\n\n\\[y = f(x) + Fehler\\]\n\nDies ist die Grundlage eines Regressionsmodells. Regressionsmodelle sind nichts anderes als eine Speziefietzierung dieser Frage. Mit einem Regressionsmodell, k√∂nnen wir die Funktion, die auf \\(x\\) angewendet werden muss, genauer beschreiben.\nDies ist die allgemeine Formel der Regression:\n\n\\[y_{i} = b_{0} + b_{1}~x_{1} + e_{i}\\]\n\n\n\\(b_{0} =\\) \\(y\\)-Achsenabschnitt, Konstante, oder Interzept:\n\nDer Wert von \\(y\\) bei einer Auspr√§gung von 0 in \\(x\\).\n\n\\(b_{1} =\\) Regressionsgewicht des Pr√§diktors oder die Steigung der Regressionsgerade.\n\nInterpretation: die Steigung der Geraden l√§sst erkennen, um wie viele Einheiten \\(y\\) zunimmt, wenn \\(x\\) um eine Einheit zunimmt\n\n\\(e_{i} =\\) Regressionsresiduum (kurz: Residuum), Residualwert oder Fehlerwert:\n\nDie Differenz zwischen einem vorhergesagten (\\(\\hat{y}\\)) und beobachteten (\\(y\\)) \\(y\\)-Wert.\nJe gr√∂√üer die Fehlerwerte, umso gr√∂√üer ist die Abweichung eines beobachteten vom vorhergesagten Wert.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "3. Linerare Regression"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/hierarchische_daten.html",
    "href": "mlm_seminar_sose23/hierarchische_daten.html",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Achtung üöß\n\n\n\nDies ist ein ‚Äúlebendiges‚Äù Dokument. Es ist m√∂glich, dass einige Aktualisierungen und Erg√§nzungen nach der Sitzung vorgenommen werden.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "2. Hierarchische Daten"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/hierarchische_daten.html#ihre-aufgabe",
    "href": "mlm_seminar_sose23/hierarchische_daten.html#ihre-aufgabe",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "Ihre Aufgabe",
    "text": "Ihre Aufgabe\n\nFinden Sie sich in Ihren Gruppen zusammen und √ºberlegen Sie sich ein passendes Beispiel.\n\n\n\nWo k√∂nnten hierarchische Daten in Ihrem Bereich vorkommen?\nWie w√ºrden diese aussehen?\n\nWie viele Ebenen w√§ren angemessen, um einen repr√§sentativen Eindruck der Variation zwischen den Beobachtungen zu erhalten?\n\nWelche Probleme w√ºrden sich ergeben, wenn Sie eine oder mehrere Beobachtungsebenen au√üer Acht lassen w√ºrden?\n\nAuf welcher Ebene findet die meiste Variation statt?\n\nZeichnen Sie ein Bild der hierarchischen Datenstruktur.\n\n\n\nNutzen Sie diese Anregungen, um in Ihrer Gruppe das Konzept der hierarchischen Daten besser zu verstehen und auf Ihre spezifischen Anwendungsf√§lle anzuwenden. Diskutieren Sie die verschiedenen Aspekte und identifizieren Sie m√∂gliche Herausforderungen, die sich aus der Verwendung hierarchischer Daten in Ihrem Kontext ergeben k√∂nnten.\n\n\n\n\n‚àí+\n20:00",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "2. Hierarchische Daten"
    ]
  },
  {
    "objectID": "about/about_cogmod.html",
    "href": "about/about_cogmod.html",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "",
    "text": "\\[\\text{Wiener}(y|\\alpha, \\tau, \\beta, \\delta) =\n\\frac{\\alpha^3}{(y-\\tau)^{3/2}} \\exp \\! \\left(- \\delta \\alpha \\beta -\n\\frac{\\delta^2(y-\\tau)}{2}\\right) \\sum_{k = - \\infty}^{\\infty} (2k +\n\\beta) \\phi \\! \\left(\\frac{2k \\alpha + \\beta}{\\sqrt{y - \\tau}}\\right)\\]\nHier finden Sie alle n√∂tigen Informationen zum Seminar, sowie alle Skripte, Aufgaben und Links zur notwendigen Software.",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "about/about_cogmod.html#allgemeine-materialien-f√ºr-das-seminar",
    "href": "about/about_cogmod.html#allgemeine-materialien-f√ºr-das-seminar",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "Allgemeine Materialien f√ºr das Seminar",
    "text": "Allgemeine Materialien f√ºr das Seminar\n\nWichtige Informationen werden auf dem Teams Channel des Seminars ver√∂ffentlicht:\n\nBeitrittslink zum Teams Channel\nKursmaterialien wie Literatur, R-Skripte und Pr√§sentationen finden Sie hier auf unserer Website\n\nWann: Mittwochs von 12:15 - 13:45 Uhr (25.10.23 - Mo. 07.02.24).\nWo: Raum 01-211 (Kleiner H√∂rsaal) im Psychologischen Institut (Binger Str.)",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "about/about_cogmod.html#inhalt-des-seminars",
    "href": "about/about_cogmod.html#inhalt-des-seminars",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "Inhalt des Seminars",
    "text": "Inhalt des Seminars\n\nMathematische Modelle kognitiver Prozesse sind ein machtvolles Werkzeug, um spezifische kognitive Prozesse wie beispielsweise Verarbeitungsgeschwindigkeit, exekutive Funktionen oder Arbeitsged√§chtniskapazit√§t genauer abzubilden. Die mathematische Formalisierung dieser Prozesse erm√∂glicht es, verbale Theorien in empirisch testbare Modelle zu √ºberf√ºhren, die eine Ableitung und √úberpr√ºfung spezifischer Hypothesen und Vorhersagen √ºber bspw. experimentelle Effekte erm√∂glichen. Ein Beispiel f√ºr ein sehr erfolgreich angewandtes Modell in der kognitiven Forschung ist das Diffusionsmodell, welches die Verarbeitungsgeschwindigkeit von einfachen Wahlreaktionszeitaufgaben modelliert. Das Seminar wird einen √úberblick √ºber die theoretischen Grundlagen und g√§ngigen Modelle zur mathematischen Modellierung verschiedener Arbeitsged√§chtnisprozesse geben. Im praktischen Teil des Seminars werden Anhand unterschiedlicher kognitiver Modelle wie des Diffusionsmodells die Modellimplementierung in R, die Sch√§tzung anhand empirischer Daten sowie die Bewertung und Interpretation der gesch√§tzten Modellparameter einge√ºbt.",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "about/about_cogmod.html#literatur",
    "href": "about/about_cogmod.html#literatur",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "Literatur",
    "text": "Literatur\n\n\n\n\n\nKlick on it!\n\n\n\nUnter dem Paperpile Repository finden Sie die relevante Literatur f√ºr jede Seminareinheit. Unter Termin 1 finden Sie das Lehrbuch Computational modeling of cognition and behavior, an welchem sich die Seminarinhalte orientieren. Dort k√∂nnen Sie die Seminareinheiten nachlesen und vertiefen. Zus√§tzlich gibt es zu jedem Termin weiterf√ºhrende und vertiefende Literatur, wie bspw. Tutorial-Paper zu unterschiedlichen Modellarten oder R-Paketen.",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "about/about_cogmod.html#fahrplan",
    "href": "about/about_cogmod.html#fahrplan",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "Fahrplan",
    "text": "Fahrplan\n\n\n\nDatum\nThema\nSlides\nScripts\n\n\n\n\n25.10.2023\nOrganisation und Ablauf\n\n\n\n\n08.11.2023\nEinf√ºhrung: Grundlagen der Modellierung\n\n\n\n\n15.11.2023\nEinf√ºhrung II: Grundlagen der Modellierung\n\n\n\n\n22.11.2023\nParametersch√§tzung I: Diskrepanzfunktionen & Sch√§tzalgorithmen\n\n\n\n\n29.11.2023\nParametersch√§tzung II: Maximum Likelihood & Beyond\n\n\n\n\n06.12.2023\nParametersch√§tzung III: Hands On in R Parameter Estimation\n\n\n\n\n13.12.2023\nMultinomial Processing Tree Models (Theorie)\n\n\n\n\n20.12.2023\nAnwendung von MPT Modellen (R-Sitzung)\n\n\n\n\n10.01.2024\nDrift Diffusion Models (Theorie)\n\n\n\n\n17.01.2024\nDrift Diffusion Models (Anwendung)\n\n\n\n\n24.01.2023\nMixture Models (Theorie)\n\n\n\n\n31.01.2024\nMixture Models (Anwendung)\n\n\n\n\n07.02.2024\nPuffersitzung",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "about/about_cogmod.html#begleitende-√ºbung",
    "href": "about/about_cogmod.html#begleitende-√ºbung",
    "title": "Seminar Fortgeschrittene statistische Methoden II (3)",
    "section": "Begleitende √úbung",
    "text": "Begleitende √úbung\n\nDas Seminar findet in Absprache mit der R-√úbung statt. In der √úbung werden die Grundlagend Programmiersprache R vermittelt. Sie werden im Umgang mit Daten geschult und verschiedene Techniken zur Datenaufbereitung erlernen. Dieser Teil der √úbung findet im ersten Teil des Semesters statt. Sie sollten f√ºr eine der beiden √úbungen angemeldet sein, entweder am Montag oder am Mittwoch. Besuchen das Tutorium! Erfahrungsgem√§√ü k√∂nnen viele Fragen und Startschwierigkeiten im Umgang mit R im Tutorium gut aufgefangen und gel√∂st werden. Im zweiten Teil des Semesters findet eine zweite, vertiefende √úbungen statt. Dieses baut auf den Grundkenntnissen, die Sie im ersten Teil des Semesters erlernt haben werden, auf. Im zweiten Teil des Semesters besuchen Sie diese √úbung entweder bei Hr. Alanis oder Fr.¬†H√ºlsemann. Die Termine f√ºr die √úbungen √§ndern sich nicht. Sie m√ºssen die √úbung nicht wechseln, alle R Inhalte die spezifisch f√ºr das Seminar sind, werden an einem Termin im Seminar behandelt und vertieft. Dieser Termin wird auf den Inhalten der bisherigen √úbungen aufbauen. Wir haben eine Reihe von Materialien zusammengestellt, um Ihnen den Einstieg in die Programmiersprache R zur erleichtern. Diese k√∂nnen Sie unter dem folgenden Link erreichen:\n\n\n\nR-Kurs-Buch von der Abteilung Analyse und Modellierung komplexer Daten.\nR for Datascience von Hadley Wickham.\nR Cheatsheets f√ºr alle wichtigen Packages und Basisfunktionen.",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Allgemeine Informationen",
      "Kursinhalt und Tutorium"
    ]
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop.html",
    "href": "scripts/ML Workshop/ML_Workshop.html",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "",
    "text": "Im letzten Seminar haben wir sehr ausf√ºhrlich √ºber Maximum Likelihood Estimation (MLE) gesprochen. Heute werden wir einige √úbungen dazu in R programmieren, um ein besseres Verst√§ndnis f√ºr diese Methode zu entwickeln.\nDas Grundprinzip der Maximum-Likelihood-Sch√§tzung besteht darin, die Parameter einer statistischen Verteilung so zu bestimmen, dass die Wahrscheinlichkeit, die beobachteten Daten gegeben bestimmter Parameterwerte, maximiert wird. Gegeben eine Verteilungsfunktion \\(f(x;\\theta)\\), wobei \\(x\\) die beobachteten Daten und \\(\\theta\\) die unbekannten Parameter sind, wird die Likelihood-Funktion definiert als \\[L(\\theta|x)=\\prod_{i=1}^{n} f(x_i;\\theta)\\], wobei \\(n\\) die Anzahl der Datenpunkte ist.\nDas Maximum-Likelihood-Sch√§tzverfahren besteht darin, die Werte von \\(\\theta\\) zu finden, die die Likelihood-Funktion maximieren. Dies kann durch Maximierung des Logarithmus der Likelihood-Funktion mathematisch vereinfacht werden, daher wird oftmals die Log-Likelihood Funktion maximiert und anstelle des Produktes, die Summe √ºber alle Funktionswerte gebildet:\n\\[\\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log f(x_i;\\theta)\\]\n\n\nNehmen wir an, wir haben an einer Sttichprobe die Intelligenz·∫Éerte erhoben und m√∂chten nun den Mittelwert des IQs anhand der Daten mit MLE sch√§tzen. Hierzu brauchen wir zun√§chst eine Dichtefunktion, √ºber die wir die Likelihood berechnen k√∂nnen. Da der IQ in der Population normalverteilt ist k√∂nnen wir hierf√ºr die Normaverteilung heranziehen um eine Likelihoodfunktion zu definieren:\n\\[f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]\nalso ist die Likelihoodfunktion gegeben als\n\\[L(\\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}\n\\] bzw. vereinfacht sich zu folgender Formel, wenn wir den Logarhitmus nehmen:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Workshop: Hands on MLE in R",
      "ML Workshop"
    ]
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop.html#einf√ºhrung",
    "href": "scripts/ML Workshop/ML_Workshop.html#einf√ºhrung",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "",
    "text": "Im letzten Seminar haben wir sehr ausf√ºhrlich √ºber Maximum Likelihood Estimation (MLE) gesprochen. Heute werden wir einige √úbungen dazu in R programmieren, um ein besseres Verst√§ndnis f√ºr diese Methode zu entwickeln.\nDas Grundprinzip der Maximum-Likelihood-Sch√§tzung besteht darin, die Parameter einer statistischen Verteilung so zu bestimmen, dass die Wahrscheinlichkeit, die beobachteten Daten gegeben bestimmter Parameterwerte, maximiert wird. Gegeben eine Verteilungsfunktion \\(f(x;\\theta)\\), wobei \\(x\\) die beobachteten Daten und \\(\\theta\\) die unbekannten Parameter sind, wird die Likelihood-Funktion definiert als \\[L(\\theta|x)=\\prod_{i=1}^{n} f(x_i;\\theta)\\], wobei \\(n\\) die Anzahl der Datenpunkte ist.\nDas Maximum-Likelihood-Sch√§tzverfahren besteht darin, die Werte von \\(\\theta\\) zu finden, die die Likelihood-Funktion maximieren. Dies kann durch Maximierung des Logarithmus der Likelihood-Funktion mathematisch vereinfacht werden, daher wird oftmals die Log-Likelihood Funktion maximiert und anstelle des Produktes, die Summe √ºber alle Funktionswerte gebildet:\n\\[\\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log f(x_i;\\theta)\\]\n\n\nNehmen wir an, wir haben an einer Sttichprobe die Intelligenz·∫Éerte erhoben und m√∂chten nun den Mittelwert des IQs anhand der Daten mit MLE sch√§tzen. Hierzu brauchen wir zun√§chst eine Dichtefunktion, √ºber die wir die Likelihood berechnen k√∂nnen. Da der IQ in der Population normalverteilt ist k√∂nnen wir hierf√ºr die Normaverteilung heranziehen um eine Likelihoodfunktion zu definieren:\n\\[f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]\nalso ist die Likelihoodfunktion gegeben als\n\\[L(\\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}\n\\] bzw. vereinfacht sich zu folgender Formel, wenn wir den Logarhitmus nehmen:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Workshop: Hands on MLE in R",
      "ML Workshop"
    ]
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop.html#mle-in-r",
    "href": "scripts/ML Workshop/ML_Workshop.html#mle-in-r",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "2 MLE in R",
    "text": "2 MLE in R\n\n2.1 √úbung 1: MLE by Hand in R\nUm in R mit der Likelihoodfunktion zu arbeiten, m√ºssen wir zun√§chst Daten simulieren. Hierzu benutzen wir die Funktion rnorm(). Bitte nutzt zun√§chste die Hilfefunktion, um mit rnorm() eine Stichproben von 10000 Werten zu genieren (N = 100), mit dem Mittelwert \\(100\\) und einer Standardabweichung von \\(15\\). Speichert den Output in der Variable ‚Äúiq‚Äù ab. Berechnet f√ºr die gezogene Stichprobe separat Mittelwert und Standardabweichung\n\n\nCode\nset.seed(666)\n# Stichprobe von Werten generieren\niq &lt;- rnorm(100,100,15)\n\n# Mittelwert und Standardabweichung berechnen\n\nmean(iq)\n\n\n[1] 98.99997\n\n\nCode\nsd(iq)\n\n\n[1] 15.44065\n\n\nZun√§chst wollen wir versuchen, die Likelihoodfunktion in R Code zu √ºbertragen. Nehmt hierzu die Gleichung der Log-Likelihoodfunktion, die wir weiter oben definiert haben:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]\nund dr√ºckt sie in R-Code aus. Ihr ben√∂tigt dazu folgende mathematischen Funktionen:\n\n\n\nFunktion\nCode\n\n\n\n\nSumme Bilden\nsum()\n\n\nQuadrieren\nx^2\n\n\nLogarhitmus\nlog()\n\n\n\\(\\pi\\)\nPi\n\n\nn\nStichprobengr√∂√üe (hier: 100)\n\n\n\nDefiniert zun√§chst zwei Variablen f√ºr unterschiedliche Parametervorschl√§ge f√ºr den Mittelwert von \\(100\\) (=low_iq) und \\(120\\) (high_iq),die Standardabweichung (=sigma) ist f√ºr beide Samples gleich (\\(\\sigma\\) = 15). Als Daten nutzen wir die generierten IQ Werte iq_low und iq_high. In der Gleichung sind \\(x\\) die Daten, also die IQ-Werte aus unserem iq Vektor, \\(\\sigma\\) ist die Standardabweichung und \\(\\mu\\) die unterschiedlichen Vorschl√§ge f√ºr die Mittelwerte, als entweder high_iq oder low_iq. Stellt nun die Gleichung f√ºr beide Parametervorschl√§ge (high vs.¬†low) in R auf. Speichert die Ergebnisse unter den Variablen ll_low und ll_high ab.\n\n\nCode\n# Define sigma and mu\nhigh_iq &lt;- 120\nlow_iq &lt;- 100\nN &lt;- 100\n\nsigma &lt;- 15\n\n\n# Define LL-Equation\nll_low &lt;- -N/2 * log(2*pi*sigma^2) - 1/(2*sigma^2) * sum((iq - low_iq)^2)\nll_high &lt;- -N/2 * log(2*pi*sigma^2) - 1/(2*sigma^2) * sum((iq - high_iq)^2)\n\n\nIhr habt nun f√ºr beide Parametervorschl√§ge, also einmal f√ºr einen Mittelwert von 100 und einmal von einem Mittelwert von 120, die log-likelihood f√ºr die vorliegenden Daten berechnet. Welcher Mittelwert ist nach dieser Likelihood unter den gegebenen Daten wahrscheinlicher ?\n\n\n2.2 Exkurs: Funktionen in R\nFunktionen sind in der Programmierung wichtige Bausteine, um Code wiederverwendbar zu machen und komplexe Aufgaben zu strukturieren. Eine nimmt in der Regel Eingabewerte (Argumente) entgegen, f√ºhrt Operationen oder Berechnungen durch und gibt ein Ergebnis zur√ºck. In R k√∂nnen Funktionen mit dem Schl√ºsselwort function definiert werden. Die Syntax besteht aus dem Funktionsnamen, den Eingabe-Parametern in Klammern, den auszuf√ºhrenden Anweisungen innerhalb des Funktionsk√∂rpers und dem R√ºckgabewert mit return(). Funktionen in R k√∂nnen dann mit den angegebenen Argumenten aufgerufen werden, um den gew√ºnschten Code auszuf√ºhren. Die Verwendung von Funktionen erleichtert das Schreiben, Lesen und Verstehen von Code, da Aufgaben in kleine, wiederverwendbare Einheiten aufgeteilt werden k√∂nnen.\nHier ein einfaches Beispiel einer Funktion, die die Quadratzahl des Inputarguments ausgibt:\n\n\nCode\n# Funktion zur Berechnung der Quadratzahl\nsquare &lt;- function(x) {\n  result &lt;- x^2\n  return(result)\n}\n\n# Verwendung der Funktion\nnum &lt;- 5\nsquared_num &lt;- square(num)\nprint(squared_num)\n\n\n[1] 25\n\n\nInnerhalb einer Funktion in R kann auf die Input-Argumente zugegriffen werden, indem man ihre Namen verwendet. Die Input-Argumente werden in der Funktion als Parameter definiert. Du kannst diese Parameter dann innerhalb der Funktion verwenden, um auf die √ºbergebenen Werte zuzugreifen und damit Berechnungen oder Operationen durchzuf√ºhren.\nZum Beispiel, wenn wir eine Funktion addition() definieren m√∂chten, die zwei Zahlen addiert, k√∂nnten wir die Input-Argumente a und b verwenden:\n\n\nCode\naddition &lt;- function(a, b) {\n  sum &lt;- a + b\n  return(sum)\n}\n\naddition(2,2)\n\n\n[1] 4\n\n\n\n\n2.3 √úbung 2: MLE Using optim()\n\nDiskrepanzfunktion definieren\nNun haben wir im Prinzip ‚Äúby Hand‚Äù eine MLE Sch√§tzung durchgef√ºhrt - zwar nicht iterativ, denn haben wir haben nur zwei m√∂gliche Parameterwerte im Lichte der gegebenen Daten nach der MLE bewertet! R bietet aber auch die M√∂glichkeit, mit der Funktion optim(), eine SIMPLEX Optimierung nach einer gegebenen Diskrepanzfunktion durchzuf√ºhren. Dazu m√ºssen wir der Funktion allerdings eine Funktion √ºbergeben.\nUm nun die optim() zu nutzen im iterativ Parameter nach MLE zu sch√§tzen und durch simplex zu minimieren, m√ºssen wir die gleiche log-likelihood Funktion von √úbung 1 in eine Funktion √ºberf√ºhren. Das ist ganz einfach, denn wir k√∂nnen uns nun, da wir das Grundprinzip von MLE verstanden haben, das Leben mit der in R verf√ºgbaren dnorm() Funktion erleichtern. Diese berechnet ebenfalls die Wahrscheinlichkeit (genauer die Dichte) f√ºr Datenpunkte, gegeben bestimmter Parameter:\n\n\nCode\n# Unsere Gleichung\nll_low &lt;- -100/2 * log(2*pi*sigma^2) - 1/(2*sigma^2) * sum((iq - low_iq)^2) \nprint(ll_low)\n\n\n[1] -415.3721\n\n\nCode\n# dnorm() aus R\nll_dnorm &lt;- sum(dnorm(iq,mean=low_iq,sd=sigma,T))\nprint(ll_dnorm)\n\n\n[1] -415.3721\n\n\nEure Aufgabe ist es nun, eine Funktion zu definieren, die sie aufsummierte log-likelihood ausgibt, wenn Ihr Parameterwerte eingebt. Dazu nutzt ihr die folgende Funktionen aus R:\n\n\n\nFunktion\nCode\n\n\n\n\nSumme Bilden\nsum()\n\n\nLikelihood\ndnorm(daten,mean=,sd=, log=TRUE)\n\n\nLogarhitmus\nlog()\n\n\n\nDie Funktion soll folgende Input-Argumente besitzen:\n\nEinen Vektor Daten (unsere IQ Daten sind ein Vektor)\nEinen Vektor theta, der nur zwei Eintr√§ge enth√§lt - theta¬†ist der Argumentname, um innerhalb der Funktion auf den Input zuzugreifen. Was ihr letztendlich der Funktion als theta √ºbergebt, muss nicht theta hei√üen !\n\nWeiterhin soll diese Funktion die aufsummierte log-Likelihood ausgeben. Definiert diese Funktion unter dem Namen MLE. Die Inputargumente m√ºssen wie im oberen Beispiel einer einfachen Funktion nur mit Namen definiert werden, nicht mit Datentyp. Diesen habe ich nur zum Verst√§ndnis mit angegeben.\n2.) M√ºssen folgende Operationen innerhalb der Funktion ausgef√ºhrt werden\n\nBerechnung der Likelihood unter der verwendung von dnorm(). b.) Aufsummierung der berechneten Likelihood mit sum()\nBerechnung der Deviance - hierzu muss die aufsummierte Likelihood mal -2\ngenommen werden.\n\nWir k√∂nnen hierbei auf die Berechnung des Logarhitmus verzichten, da dnorm() schon den die log-Likelihood mit ausgibt. Hierzu muss allerdings das Argument log = TRUE gesetzt werden ! Zur Erinnerung, auf bestimmte Elemente eines Vektors greift ihr folgenderma√üen zu (dies ist wichtig zu wissen, da Ihr mit den Inputwerten innerhalb der Funktion arbeiten m√ºsst):\n\n\nCode\n# Vektor Definieren\nvektor &lt;- c(1,2,3)\n\n# Erstes Element\n\nvektor[1]\n\n\n[1] 1\n\n\nCode\n# Zweites Element\n\nvektor[2]\n\n\n[1] 2\n\n\nCode\n# Drittes Element\n\nvektor[3]\n\n\n[1] 3\n\n\n3.) Es muss mit return() das Endprodukt zur√ºckgeben, wie in den beiden einfachen Beispielen vorher !\n\n\nCode\n### YOUR CODE HERE \n\nMLE &lt;- function(Daten, theta) \n{\n  mu &lt;- theta[1]\n  sigma &lt;- theta[2]\n  \n  LL &lt;- -2*(sum(dnorm(Daten,mean=mu,sd=sigma,log = T)))\n  \n  return(LL)\n  \n}\n\n# Test your function with different values for theta\ntheta &lt;- c(80,20)\nMLE(iq,theta)\n\n\n[1] 932.1913\n\n\n\n\nOptimieren der Parameter mit optim()\nNun da unsere ML-Diskrepanzfunktion funktioniert, m√ºssen wir diese nat√ºrlich minimieren - dazu k√∂nnen wir die Funktion optim() nutzen, die in R zur Verf√ºgung steht. Mit optim() ist standardm√§√üig der SIMPLEX -Algorithmus eingestellt. Es k√∂nnen aber auch andere Algorhithmen genutzt werden. Es werden der Funktion drei Hauptargumente √ºbergeben:\n\npar - ein Vektor mit den Startwerten der Parametersch√§tzung. Die Startwerte sollten nicht √ºberm√§√üig von den erwarteten Werten abweichen. Sch√§tzt man also einen Mittelwert von IQ Daten, macht es keinen Sinn, den Startwert f√ºr den Mittelwert auf 1 zu setzen, da der ‚Äúwahre Wert‚Äù vermutlich zwischen 75 und 150 liegen wird. Gleiches gilt f√ºr die Standardabweichung.\nfn= - die Diskrepanzfunktion die es zu minimieren gilt. Hier die von uns definierte MLE() Funktion.\nDie Daten - diese √ºbergebt ihr mit dem Namen, den Ihr in eurer Funktion verwendet habt, also hier Daten = iq.\n\nOptimiert nun die definierte Funktion mit optim() und speichert die Ergebnisse im Objekt fit.\n\n\nCode\n# YOUR CODE HERE\n\nfit &lt;- optim(par=c(mu=50,sigma=10), fn =MLE, Daten=iq)\n\nfit$par\n\n\n      mu    sigma \n99.00413 15.36639 \n\n\nCode\n# Biased Fit Example \n\niq_pop &lt;- rnorm(1000,mean=100,sd=15)\niq_bias &lt;- sample(iq_pop,25)\n\nmean(iq_bias)\n\n\n[1] 103.8359\n\n\nCode\n# Fitting Sample\nfit &lt;- optim(par=c(mu=50,sigma=10), fn =MLE, Daten=iq_bias)\n\nfit$par\n\n\n       mu     sigma \n103.84127  13.60439",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Workshop: Hands on MLE in R",
      "ML Workshop"
    ]
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop.html#fazit",
    "href": "scripts/ML Workshop/ML_Workshop.html#fazit",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "3 Fazit",
    "text": "3 Fazit\nIn diesem Tutorial haben wir uns mit der Maximum-Likelihood-Sch√§tzung (MLE) in R besch√§ftigt und die Funktion `optim()` verwendet, um die Sch√§tzung durchzuf√ºhren. Zun√§chst haben wir die Likelihood-Funktion selbst definiert und verschiedene Parameterwerte getestet, um das Konzept der MLE besser zu verstehen.\nDurch die Verwendung von `optim()` konnten wir die MLE iterativ implementieren und die optimalen Parameterwerte finden, die die Likelihood-Funktion maximieren (oder die Deviance minimieren). Wir haben gesehen, dass `optim()` eine effiziente Methode zur numerischen Optimierung ist und verschiedene Algorithmen zur Verf√ºgung stellt.\nDie Maximum-Likelihood-Sch√§tzung ist ein leistungsstarkes Werkzeug, um Parameter in statistischen Modellen zu sch√§tzen. Es erm√∂glicht uns, die Wahrscheinlichkeit der beobachteten Daten unter verschiedenen Annahmen zu maximieren und die besten Parameterwerte zu ermitteln.",
    "crumbs": [
      "Seminar kognitive Modellierung",
      "Workshop: Hands on MLE in R",
      "ML Workshop"
    ]
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). Case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#fortgeschrittene-dplyr-funktionen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#fortgeschrittene-dplyr-funktionen",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). Case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "title": "Advanced Dplyr",
    "section": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen",
    "text": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen\nDie case_when Funktion in dplyr erm√∂glicht es, basierend auf bestimmten Bedingungen verschiedene Werte f√ºr eine Spalte in einem Datensatz auszuw√§hlen und abh√§ngig vom Variablenwert einen neue Variable zu erstellen. Es ist eine sehr einfache M√∂glichkeit, if-else Statements in eine dplyr-Pipeline zu integrieren.\nDie Syntax eines case_when() Befehles entspricht einer einfachen if oder if-else Verkn√ºpfung. Eine if-else Verkn√ºpfung pr√ºft eine Bedingung und f√ºhrt wenn diese Erf√ºllt ist einen definierten Befehl aus. Ist die Bedingung nicht erf√ºllt, wird andernfalls (else) ein anderer Befehl ausgef√ºhrt:\n\n\n# Vektor von Zahlen darauf testen, ob sie gerade oder ungerade sind:\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei geteilt keinen Rest hat, dann schreibe Gerade, ansonsten Ungerade.\n\nifelse(zahlen %% 2 == 0,\"Gerade\",\"Ungerade\")\n\ncase_when() funktioniert nach der Gleichen Logik:\n\n\n\nDabei wird immer zuerst die if-Bedinungen und deren Output definiert und anschlie√üend mit TRUE die else Bedingung, welche angibt was passiert wenn die if - Bedingung nicht zutrifft:\n\n\n\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei\n# geteilt keinen Rest hat, dann schreibe Gerade, \n# ansonsten Ungerade.\n\ncase_when(zahlen %% 2 == 0 ~ \"Gerade\",\n          TRUE ~\"Ungerade\")\n\nDer Unterschied von case_when() und ifelse() ist, dass mit case_when() auch mehrere Bedingungen definiert werden k√∂nnen (z.B. wenn eine Variable in mehrere Kategorien eingeteilt werden soll):\n\nHier gibt es auch ein finales else Statement, dieses muss aber nicht sein, solange die Kategorien alle F√§lle abdecken!\n\n2.0.1 case_when: Beispiele\nDas folgende ist ein einfaches Beispiel, bei dem case_when() verwendet wird, um in einem Datensatz eine neue Spalte Alter_Kategorie anhand des Werts in der Spalte Alter zu kategorisieren. Wenn eine neue Spalte erstellt werden soll, muss case_when() immer mit mutate() kombiniert werden:\n\n# Beispiel Datensatz erstellen\ndf &lt;- data.frame(Name = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45))\nhead(df)\n\n# mutate und case_when verwenden, um neue Variable in Abh√§ngigkeit vom Alter zu erstellen:\ndf %&gt;% \n  mutate(Alter_Kategorie = case_when(\n    Alter &lt;= 25 ~ \"jung\",\n    Alter &gt; 25 & Alter &lt;= 35 ~ \"mittel\",\n    Alter &gt; 35 ~ \"alt\"\n  ))\n\nEin weiteres Beispiel haben wir letzte Woche bei der MPT-Modellierung der Daten von Frenken et al.¬†gesehen. Im Datensatz ist shoot als 0 und not shoot als 1 kodiert. F√ºr die MPT Modellierung ben√∂tigen wir aber f√ºr jede Kategorie (Black / Gun, Black / Phone, White / Gun, White / Phone) die Hits und Misses, also die Fehlerraten. Der Datensatz hat praktischerweise eine Spalte, die genau kodiert, was die VP gesehen hat:\n\n\nhead(Study_2_dm)\n\n# A tibble: 6 √ó 6\n  subj_idx stimulus stim     rt response condition\n     &lt;dbl&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;    \n1        0 gun      bg    0.506        0 black    \n2        0 phone    wp    0.437        0 white    \n3        0 phone    wp    0.483        0 white    \n4        0 phone    bp    0.594        1 black    \n5        0 phone    wp    0.552        1 white    \n6        0 gun      wg    0.417        1 white    \n\n\nIn der zweiten Spalte stimulus ist angebenen, welches Objekt der jeweils zusammen mit der Hautfarbe gezeigt wurde. Da wir wissen, dass nur bei ‚Äúgun‚Äù geschossen werden darf, k√∂nnen wir nun in Kombination mit response (0 - shoot, 1 - not shoot) die Hits mit case_when() in einer neuen Spalte ACC kodieren.\nDazu Verkn√ºpfen wir hier zwei Bedingungen mit dem & Operator. Die erste Bedingung bezieht sich auf die Spalte stimulus, hier muss gepr√ºft werden, welcher Stimulus gezeigt wurde (Gun vs.¬†Phone). Die zweite Bedingung bezieht sich auf die Spalte response. Hier muss gepr√ºft werden, ob geschossen wurde oder nicht. Ingesamt m√ºssen also vier Bedinungen definiert werden, f√ºr jede Kombination von Objekt und Response:\n\nAccuracy in Abh√§ngigkeit von Gegebener Response und Stimulus\n\n\nStimulus\nResponse\nAccuracy\n\n\n\n\nGun\n0\n1\n\n\nGun\n1\n0\n\n\nPhone\n0\n0\n\n\nPhone\n1\n1\n\n\n\nDies m√ºssen wir nun in ein case_when() Befehl √ºbernehmen\n\nMit mutate() die neue Outputspalte benennen\nInnerhalb von mutate() mit case_when() die Accuracy in Abh√§ngigkeit der Spalten Stimulus und Response umkodieren:\n\n\n\nfreq_dat &lt;- Study_2_dm %&gt;% mutate(ACC = case_when(stimulus == \"gun\" & response == 0 ~ 1,\n                                                  stimulus == \"gun\" & response == 1 ~ 0,\n                                                  stimulus == \"phone\" & response == 1 ~ 1,\n                                                  stimulus ==\"phone\" & response == 0 ~ 0))\n\nAnschlie√üend m√ºssen wir nun die Hits und Misses ausz√§hlen. Generell eignen sich zum Ausz√§hlen von bestimmten Bedingungskombinationen oder Trials die Funktionen group_by(), summarise() und n(). n() ist eine einfache Z√§hlfunktion, welche innerhalb von group_by() %&gt;% summarise() dazu f√ºhrt, dass die alle Beobachtungen der gruppierten Variablen (z.B. Subject & Bedingung) innerhalb von summarise() gez√§hlt werden.\nAlso zum Beispiel, wieviele Beobachtung von Subject 1 gibt es in Bedingung A, B und C. Dies macht aber nur Sinn, wenn ihr Daten auf Trial-Ebene (also f√ºr jede Versuchsperson alle Antworten √ºber das ganez Experiment) vorliegen habt. Dies ist hier der Fall, da f√ºr jede Person und jede Bedingung, die diese Person durchlaufen hat, die gegebenen Antworten im Datensatz in der Spalte responses vorliegen.\n\n\nfreq_dat &lt;- freq_dat %&gt;% group_by(subj_idx,stim) %&gt;% \n  summarise(hits = sum(ACC), \n            ntrials=n(), \n            miss=ntrials-hits)\n\n`summarise()` has grouped output by 'subj_idx'. You can override using the\n`.groups` argument.\n\nhead(freq_dat)\n\n# A tibble: 6 √ó 5\n# Groups:   subj_idx [2]\n  subj_idx stim   hits ntrials  miss\n     &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;\n1        0 bg       30      31     1\n2        0 bp       28      29     1\n3        0 wg       23      27     4\n4        0 wp       28      33     5\n5        1 bg       28      30     2\n6        1 bp       16      18     2\n\n\nWas passiert hier genau ? Schritt f√ºr Schritt:\n\ngroup_by(subj_idx, stim) : Wir gruppieren zun√§chst nach Subject und Bedingung\n\nsummarise(...\n\nhits = sum(ACC) - Wir haben alle Hits mit case_when als 1 kodiert, also k√∂nnen wir die Hits einfach berechnen, indem wir diese aufsummieren.\nnTrials = n() - Ausz√§hlen wieviele Responses ein Subject in jeder stimulus Bedinungen gegeben hat (Gesamtanzahl von gegebenen Antworten in einer Bedingungen pro Person\nmiss = ntrials - hits Alles was kein Hit ist muss ein Miss sein ! Daher k√∂nnen wir einfach die Hits von der Gesamtzahl der Antworten abziehen und erhalten die Anzahl der Misses in jeder Bedinung pro Subject !"
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "title": "Advanced Dplyr",
    "section": "3 Long- und Wide-Datenformat - Datentransformation in dplyr",
    "text": "3 Long- und Wide-Datenformat - Datentransformation in dplyr\nNun haben wir die Daten von Frenken et al.¬†neu kodiert und die n√∂tigen Informationen im Datensatz, um mit MPTinR zu arbeiten. Allerdings liegen die Daten noch im sogenannten long - Format vor. Oftmals ist es jedoch notwendig, Daten entweder von einem long in ein wide Format oder umgekehrt zu transfomieren. Im Kontext von Datenanalyse und statistischer Modellierung gibt es in der Regel zwei Haupttypen von Datenformaten: wide-Format (breit-Format) und long-Format (lang-Format).\n\n3.1 Wide-Format\n\nIn einem wide Format sind die verschiedenen Merkmale einer einzigen Beobachtung in separaten Spalten dargestellt.\nEine einzige Zeile in einem breiten Datensatz repr√§sentiert eine Beobachtung.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, w√§re in einem breiten Format dargestellt, wobei jede Spalte einem bestimmten Fach entspricht.\nVorteil: Es ist einfach, schnelle √úbersichten √ºber gro√üe Datenmengen zu erhalten.\n\nBeispiel:\n\nwide_df &lt;- data.frame(Sch√ºler_ID = c(1, 2, 3), \n                      Mathe = c(89, 76, 92), \n                      Englisch = c(92, 88, 95), \n                      Wissenschaft = c(88, 72, 98))\nwide_df\n##   Sch√ºler_ID Mathe Englisch Wissenschaft\n## 1          1    89       92           88\n## 2          2    76       88           72\n## 3          3    92       95           98\n\n\n\n3.2 Long-Format\n\nIm long Format sind alle Merkmale einer einzigen Beobachtung in einer Zeile dargestellt.\nEine einzige Spalte in einem long Datensatz repr√§sentiert ein bestimmtes Merkmal.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, k√∂nnte in einem langen Format dargestellt werden, wobei jede Zeile einer bestimmten Sch√ºler-Fach-Kombination entspricht.\nVorteil: Es ist einfach, bestimmte Merkmale f√ºr verschiedene Beobachtungen zu vergleichen oder zu analysieren. Au√üerdem ist es f√ºr manche statistische Methoden, wie lineare Regression oder einer ANOVA, das bevorzugte Format.\n\nBeispiel:\n\nlong_df &lt;- data.frame(Sch√ºler_ID = c(rep(1, 3), rep(2, 3), rep(3, 3)), \n                      Fach = c(rep(\"Mathe\", 3), rep(\"Englisch\", 3), rep(\"Wissenschaft\", 3)), \n                      Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\nlong_df\n##   Sch√ºler_ID         Fach Note\n## 1          1        Mathe   89\n## 2          1        Mathe   92\n## 3          1        Mathe   88\n## 4          2     Englisch   76\n## 5          2     Englisch   88\n## 6          2     Englisch   72\n## 7          3 Wissenschaft   92\n## 8          3 Wissenschaft   95\n## 9          3 Wissenschaft   98\n\nEs ist wichtig, das Konzept des wide- und long-Formats zu verstehen, da es bei der Datenaufbereitung und Analyse eine wichtige Rolle spielt. Zum Beispiel kann ein wide -Datensatz schwer zu analysieren sein, wenn man Vergleiche zwischen bestimmten Merkmalen √ºber mehrere Beobachtungen hinweg machen m√∂chte (Beispiel Ergebnisse der Diffusionsmodellierung!). Hier ist es oft besser, den Datensatz in ein long-format zu bringen.\n\n\n3.3 pivot - Funktionen in dplyr\nDie Funktionen pivot_wider und pivot_longer geh√∂ren zu den Funktionen von dplyr und dienen dazu, Datens√§tze zu transformieren.\npivot_wider verwandelt einen long-Format Datensatz in einen wide-Format Datensatz, indem es die Werte einer bestimmten Spalte zu neuen Spalten umbenennt. Dies kann manuell durchgef√ºhrt werden, aber pivot_wider macht dies automatisch und erleichtert so die Datentransformation:\n\n\npivot_longer verwandelt einen wide-Format Datensatz in einen long-Format Datensatz, indem es die Spalten mit bestimmten Werten in einer neuen Spalte zusammenfasst.\nEin Beispiel f√ºr den Einsatz von pivot_wider:\n\n# long data example\nlong_data &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\", \"John\", \"Jane\", \"Jim\"),\n  subject = c(\"physics\", \"physics\", \"physics\", \"math\", \"math\", \"math\"),\n  score = c(85, 90, 80, 75, 80, 70)\n)\n\nlong_data\n## # A tibble: 6 √ó 3\n##   name  subject score\n##   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n## 1 John  physics    85\n## 2 Jane  physics    90\n## 3 Jim   physics    80\n## 4 John  math       75\n## 5 Jane  math       80\n## 6 Jim   math       70\n\n\n# pivot to wide format\npivot_wider(long_data, names_from = subject, values_from = score)\n## # A tibble: 3 √ó 3\n##   name  physics  math\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n## 1 John       85    75\n## 2 Jane       90    80\n## 3 Jim        80    70\n\nEin Beispiel f√ºr den Einsatz von pivot_longer:\n\n# wide data example\nwide_df &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\"),\n  Mathe_Note = c(85, 90, 80),\n  Englisch_Note = c(75, 80, 70)\n)\n\n\nwide_df\n## # A tibble: 3 √ó 3\n##   name  Mathe_Note Englisch_Note\n##   &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n## 1 John          85            75\n## 2 Jane          90            80\n## 3 Jim           80            70\n\n\n# pivot to long format\npivot_longer(wide_df, cols = c(Mathe_Note, Englisch_Note), \n             names_to = \"Sch√ºler\", values_to = \"Note\")\n## # A tibble: 6 √ó 3\n##   name  Sch√ºler        Note\n##   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n## 1 John  Mathe_Note       85\n## 2 John  Englisch_Note    75\n## 3 Jane  Mathe_Note       90\n## 4 Jane  Englisch_Note    80\n## 5 Jim   Mathe_Note       80\n## 6 Jim   Englisch_Note    70\n\n\n\n3.4 Argumente f√ºr pivot_longer und pivot_wider\npivot_longer ben√∂tigt mindestens zwei Argumente:\n\ncols: Dies ist ein Zeichenvektor, der angibt, welche Spalten im Datensatz zusammengefasst werden sollen. -Sch√ºler_ID bedeutet zum Beispiel, dass alle Spalten au√üer Sch√ºler_ID zusammengefasst werden sollen.\nnames_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die zusammengefassten Werte gespeichert werden.\nvalues_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die Werte gespeichert werden, die aus den zusammengefassten Spalten stammen.\n\n\npivot_wider ben√∂tigt mindestens zwei Argumente:\n\nnames_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Namen f√ºr die neuen Spalten verwendet werden soll.\nvalues_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Werte f√ºr die neuen Spalten verwendet werden soll.\n\n\nBeide Funktionen haben auch weitere optionale Argumente wie values_fill und names_prefix oder names_sep()um die Daten bei Bedarf weiter anzupassen.\nHier nun die Umformung der Daten von Frenken et al., welche wir vom long Format in das wide Format bringen m√ºssen:\n\n\n#| echo: true\n#| output: true\n#| warning: false\n#| code-overflow: wrap\n#| collapse: true\n\nfreq_dat %&gt;% pivot_wider(names_from = c(\"stim\"),\n                         values_from = c(\"hits\",\"miss\"),\n                         id_cols=\"subj_idx\")\n\n# A tibble: 137 √ó 9\n# Groups:   subj_idx [137]\n   subj_idx hits_bg hits_bp hits_wg hits_wp miss_bg miss_bp miss_wg miss_wp\n      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1        0      30      28      23      28       1       1       4       5\n 2        1      28      16      27      11       2       2       2       1\n 3        3      25      10      33      23       0       0       1       1\n 4        4      35      24      27      33       1       0       0       0\n 5        5      31      28      25      23       1       2       4       4\n 6        6      34      26      18      31       0       0       5       0\n 7        7      29      24      21      36       2       0       1       1\n 8        8      22      29      25      28       0       2      10       2\n 9        9      28      23      22      22       2       0       2       1\n10       10      26      35      25      24       4       0       0       3\n# ‚Ñπ 127 more rows\n\n\nWas passiert hier genau ? Schritt f√ºr Schritt:\n\nnames_from = c(stim) - Die neuen Spalten sollen aus der Spalte stim benannt werden - (bg,bp,wp,wg)\nvalues_from = c(\"hits\",\"miss\") - in den neuen Spalten sollen die Werte der Hits und Miss Spalten stehen - durch den ersten und zweiten Schritt entstehen also Spalten, die jeweils hits_bg etc. enthalten. Also die Hits aus der Bedingung ‚Äúbg‚Äù usw.\nid_cols - dies soll f√ºr jedes Subject einzeln geschehen."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#√ºbungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_stud.html#√ºbungen",
    "title": "Advanced Dplyr",
    "section": "4 √úbungen",
    "text": "4 √úbungen\n\n4.1 case_when\n1.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúNote_Kategorie‚Äù zu erstellen, die ‚ÄúSehr gut‚Äù f√ºr Noten √ºber 90, ‚ÄúGut‚Äù f√ºr Noten zwischen 80 und 90 und ‚ÄúSchlecht‚Äù f√ºr Noten unter 80 angibt.\n\ndf &lt;- data.frame(Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\n# Your Code Here\n\n2.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúBestanden‚Äù zu erstellen, um zu Pr√ºfen ob ein Sch√ºler einer bestimmten Schulform eine Pr√ºfung bestanden hat. Die Bestehensgrenzen sind wie folgt.\n-   F√ºr die Hauptschule liegt die Bestehensgrenze bei 50 %\n-   F√ºr die Realschule liegt die Bestehensgrenze bei 60 %\n-   F√ºr das Gymnasium liegt die Bestehensgrenze bei 70 %\nKodieren Sie das bestehen entweder mit ‚ÄúPass‚Äù oder ‚ÄúFail‚Äù.\n\ndf &lt;- data.frame(Note = runif(100,min=0, max=100),\n                 Schulform = sample(c(\"Gymnasium\",\"Realschule\", \"Hauptschule\"),\n                                    size = 100, replace = T))\n# Your Code here\n\n3.) Nutzen Sie die Funktion case_when und die dplyr-Library in R, um eine neue Spalte in dem Datensatz ‚Äúdf‚Äù zu erstellen, die die Einkommenskategorie jeder Person basierend auf ihrem Berufsstatus und ihrem Einkommen kategorisiert. Die Einkommenskategorien sollten wie folgt sein:\n\nF√ºr Angestellte mit einem Einkommen von bis zu 50.000: ‚Äúniedrig‚Äù\nF√ºr Angestellte mit einem Einkommen zwischen 50.000 und 75.000: ‚Äúmittel‚Äù\nF√ºr Angestellte mit einem Einkommen √ºber 75.000: ‚Äúhoch‚Äù\nF√ºr Freiberufler mit einem Einkommen von bis zu 60.000: ‚Äúniedrig‚Äù\nF√ºr Freiberufler mit einem Einkommen zwischen 60.000 und 100.000: ‚Äúmittel‚Äù\nF√ºr Freiberufler mit einem Einkommen √ºber 100.000: ‚Äúhoch‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen von bis zu 30.000: ‚Äúniedrig‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen √ºber 30.000: ‚Äúmittel_hoch‚Äù\n\n\ndf &lt;- data.frame(ID = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45),\n                 Berufsstatus = c(\"Angestellter\", \"Freiberufler\", \"Ruhest√§ndler\"),\n                 Einkommen = c(45000, 75000, 32000))\n\n\n\n4.2 Pivotting\n1.) Konvertieren Sie die folgenden Datensatz von wide to long. Erstellen Sie aus den Spalten zwei neue Spalten mit den Namen (month und index). Nutzen Sie dazu das Argument names_sep = \"_\". Die Werte sollen in die Spalte ‚ÄúN‚Äù geschrieben werden.\nTip: Sie m√ºssen bei names_to einen Vektor mit den Namen der neuen Spalten angeben.\n\ndf_wide &lt;- data.frame(\n  Jan_sales = c(10, 40, 70),\n  Feb_sales = c(20, 50, 80),\n  Mar_sales = c(30, 60, 90)\n)\n\n# Your Code here\n\n2.) Konvertieren Sie die folgendn Datensatz von long in wide.\n\n    df_long &lt;- data.frame(\n      ID = c(\"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\"),\n      month = c(\"Jan\", \"Jan\", \"Jan\", \"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\"),\n      sales = c(10, 40, 70, 20, 50, 80, 30, 60, 90))\n      \n\n    # Your Code Here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lehre@AMD",
    "section": "",
    "text": "Willkommen!\nHerzlich Willkommen zur Lehre-Homepage der Abteilung Analyse und Modellierung komplexer Daten an der Johannes Gutenberg-Universit√§t Mainz.\nAktuell finden Sie hier die Materialien f√ºr zwei Seminare zu fortgeschrittene statistische Methoden II im Sommersemester 23.\n\n\nAktuelle Seminare\n\n\n\n\n\n\n\n\n\n\nSeminar Fortgeschrittene statistische Methoden II (1)\n\n\nTermin 1: Allgemeine Informationen\n\n\n\nJos√© C. Garc√≠a Alanis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeminar Fortgeschrittene statistische Methoden II (3)\n\n\nKognitive Modellierung\n\n\n\nJan G√∂ttmann\n\n\n\n\n\n\n\n\nKeine Treffer"
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#fortgeschrittene-dplyr-funktionen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#fortgeschrittene-dplyr-funktionen",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "title": "Advanced Dplyr",
    "section": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen",
    "text": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen\nDie case_when Funktion in dplyr erm√∂glicht es, basierend auf bestimmten Bedingungen verschiedene Werte f√ºr eine Spalte in einem Datensatz auszuw√§hlen und abh√§ngig vom Variablenwert einen neue Variable zu erstellen. Es ist eine sehr einfache M√∂glichkeit, if-else Statements in eine dplyr-Pipeline zu integrieren.\nDie Syntax eines case_when() Befehles entspricht einer einfachen if oder if-else Verkn√ºpfung. Eine if-else Verkn√ºpfung pr√ºft eine Bedingung und f√ºhrt wenn diese Erf√ºllt ist einen definierten Befehl aus. Ist die Bedingung nicht erf√ºllt, wird andernfalls (else) ein anderer Befehl ausgef√ºhrt:\n\n\n\nCode\n# Vektor von Zahlen darauf testen, ob sie gerade oder ungerade sind:\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei geteilt keinen Rest hat, dann schreibe Gerade, ansonsten Ungerade.\n\nifelse(zahlen %% 2 == 0,\"Gerade\",\"Ungerade\")\n\n\ncase_when() funktioniert nach der Gleichen Logik:\n\n\n\nDabei wird immer zuerst die if-Bedinungen und deren Output definiert und anschlie√üend mit TRUE die else Bedingung, welche angibt was passiert wenn die if - Bedingung nicht zutrifft:\n\n\n\n\nCode\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei\n# geteilt keinen Rest hat, dann schreibe Gerade, \n# ansonsten Ungerade.\n\ncase_when(zahlen %% 2 == 0 ~ \"Gerade\",\n          TRUE ~\"Ungerade\")\n\n\nDer Unterschied von case_when() und ifelse() ist, dass mit case_when() auch mehrere Bedingungen definiert werden k√∂nnen (z.B. wenn eine Variable in mehrere Kategorien eingeteilt werden soll):\n\nHier gibt es auch ein finales else Statement, dieses muss aber nicht sein, solange die Kategorien alle F√§lle abdecken!\n\n2.0.1 case_when(): Beispiele\nDas folgende ist ein einfaches Beispiel, bei dem case_when() verwendet wird, um in einem Datensatz eine neue Spalte Alter_Kategorie anhand des Werts in der Spalte Alter zu kategorisieren. Wenn eine neue Spalte erstellt werden soll, muss case_when() immer mit mutate() kombiniert werden:\n\n\nCode\n# Beispiel Datensatz erstellen\ndf &lt;- data.frame(Name = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45))\nhead(df)\n\n# mutate und case_when verwenden, um neue Variable in Abh√§ngigkeit vom Alter zu erstellen:\ndf %&gt;% \n  mutate(Alter_Kategorie = case_when(\n    Alter &lt;= 25 ~ \"jung\",\n    Alter &gt; 25 & Alter &lt;= 35 ~ \"mittel\",\n    Alter &gt; 35 ~ \"alt\"\n  ))"
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "title": "Advanced Dplyr",
    "section": "3 Long- und Wide-Datenformat - Datentransformation in dplyr",
    "text": "3 Long- und Wide-Datenformat - Datentransformation in dplyr\nNun haben wir die Daten von Frenken et al.¬†neu kodiert und die n√∂tigen Informationen im Datensatz, um mit MPTinR zu arbeiten. Allerdings liegen die Daten noch im sogenannten long - Format vor. Oftmals ist es jedoch notwendig, Daten entweder von einem long in ein wide Format oder umgekehrt zu transfomieren. Im Kontext von Datenanalyse und statistischer Modellierung gibt es in der Regel zwei Haupttypen von Datenformaten: wide-Format (breit-Format) und long-Format (lang-Format).\n\n3.1 Wide-Format\n\nIn einem wide Format sind die verschiedenen Merkmale einer einzigen Beobachtung in separaten Spalten dargestellt.\nEine einzige Zeile in einem breiten Datensatz repr√§sentiert eine Beobachtung.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, w√§re in einem breiten Format dargestellt, wobei jede Spalte einem bestimmten Fach entspricht.\nVorteil: Es ist einfach, schnelle √úbersichten √ºber gro√üe Datenmengen zu erhalten.\n\nBeispiel:\n\n\nCode\nwide_df &lt;- data.frame(Sch√ºler_ID = c(1, 2, 3), \n                      Mathe = c(89, 76, 92), \n                      Englisch = c(92, 88, 95), \n                      Wissenschaft = c(88, 72, 98))\nwide_df\n##   Sch√ºler_ID Mathe Englisch Wissenschaft\n## 1          1    89       92           88\n## 2          2    76       88           72\n## 3          3    92       95           98\n\n\n\n\n3.2 Long-Format\n\nIm long Format sind alle Merkmale einer einzigen Beobachtung in einer Zeile dargestellt.\nEine einzige Spalte in einem long Datensatz repr√§sentiert ein bestimmtes Merkmal.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, k√∂nnte in einem langen Format dargestellt werden, wobei jede Zeile einer bestimmten Sch√ºler-Fach-Kombination entspricht.\nVorteil: Es ist einfach, bestimmte Merkmale f√ºr verschiedene Beobachtungen zu vergleichen oder zu analysieren. Au√üerdem ist es f√ºr manche statistische Methoden, wie lineare Regression oder einer ANOVA, das bevorzugte Format.\n\nBeispiel:\n\n\nCode\nlong_df &lt;- data.frame(Sch√ºler_ID = c(rep(1, 3), rep(2, 3), rep(3, 3)), \n                      Fach = c(rep(\"Mathe\", 3), rep(\"Englisch\", 3), rep(\"Wissenschaft\", 3)), \n                      Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\nlong_df\n##   Sch√ºler_ID         Fach Note\n## 1          1        Mathe   89\n## 2          1        Mathe   92\n## 3          1        Mathe   88\n## 4          2     Englisch   76\n## 5          2     Englisch   88\n## 6          2     Englisch   72\n## 7          3 Wissenschaft   92\n## 8          3 Wissenschaft   95\n## 9          3 Wissenschaft   98\n\n\nEs ist wichtig, das Konzept des wide- und long-Formats zu verstehen, da es bei der Datenaufbereitung und Analyse eine wichtige Rolle spielt. Zum Beispiel kann ein wide -Datensatz schwer zu analysieren sein, wenn man Vergleiche zwischen bestimmten Merkmalen √ºber mehrere Beobachtungen hinweg machen m√∂chte (z.b. bei Varianzanalysen). Hier ist es oft besser, den Datensatz in ein long-Format zu bringen.Umgekehrt kann es der Fall sein, das eine bestimmte Analyseform oder Modellierung die Daten im wide-Format\n\n\n3.3 pivot - Funktionen in dplyr\nDie Funktionen pivot_wider und pivot_longer geh√∂ren zu den Funktionen von dplyr und dienen dazu, Datens√§tze zu transformieren.\n\npivot_wider verwandelt einen long-Format Datensatz in einen wide-Format Datensatz, indem es die Werte einer bestimmten Spalte zu neuen Spalten umbenennt. Dies kann manuell durchgef√ºhrt werden, aber pivot_wider macht dies automatisch und erleichtert so die Datentransformation:\npivot_longer verwandelt einen wide-Format Datensatz in einen long-Format Datensatz, indem es die Spalten mit bestimmten Werten in einer neuen Spalte zusammenfasst.\n\nEin Beispiel f√ºr den Einsatz von pivot_wider:\n\n\nCode\n# long data example\nlong_data &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\", \"John\", \"Jane\", \"Jim\"),\n  subject = c(\"physics\", \"physics\", \"physics\", \"math\", \"math\", \"math\"),\n  score = c(85, 90, 80, 75, 80, 70)\n)\n\nlong_data\n## # A tibble: 6 √ó 3\n##   name  subject score\n##   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n## 1 John  physics    85\n## 2 Jane  physics    90\n## 3 Jim   physics    80\n## 4 John  math       75\n## 5 Jane  math       80\n## 6 Jim   math       70\n\n\n# pivot to wide format\npivot_wider(long_data, names_from = subject, values_from = score)\n## # A tibble: 3 √ó 3\n##   name  physics  math\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n## 1 John       85    75\n## 2 Jane       90    80\n## 3 Jim        80    70\n\n\nEin Beispiel f√ºr den Einsatz von pivot_longer:\n\n\nCode\n# wide data example\nwide_df &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\"),\n  Mathe_Note = c(85, 90, 80),\n  Englisch_Note = c(75, 80, 70)\n)\n\n\nwide_df\n## # A tibble: 3 √ó 3\n##   name  Mathe_Note Englisch_Note\n##   &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n## 1 John          85            75\n## 2 Jane          90            80\n## 3 Jim           80            70\n\n\n# pivot to long format\npivot_longer(wide_df, cols = c(Mathe_Note, Englisch_Note), \n             names_to = \"Sch√ºler\", values_to = \"Note\")\n## # A tibble: 6 √ó 3\n##   name  Sch√ºler        Note\n##   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n## 1 John  Mathe_Note       85\n## 2 John  Englisch_Note    75\n## 3 Jane  Mathe_Note       90\n## 4 Jane  Englisch_Note    80\n## 5 Jim   Mathe_Note       80\n## 6 Jim   Englisch_Note    70\n\n\n\n\n3.4 Argumente f√ºr pivot_longer und pivot_wider\npivot_longer ben√∂tigt mindestens zwei Argumente:\n\ncols: Dies ist ein Zeichenvektor, der angibt, welche Spalten im Datensatz zusammengefasst werden sollen. -Sch√ºler_ID bedeutet zum Beispiel, dass alle Spalten au√üer Sch√ºler_ID zusammengefasst werden sollen.\nnames_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die zusammengefassten Werte gespeichert werden.\nvalues_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die Werte gespeichert werden, die aus den zusammengefassten Spalten stammen.\n\n\npivot_wider ben√∂tigt mindestens zwei Argumente:\n\nnames_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Namen f√ºr die neuen Spalten verwendet werden soll.\nvalues_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Werte f√ºr die neuen Spalten verwendet werden soll.\n\n\nBeide Funktionen haben auch weitere optionale Argumente wie values_fill und names_prefix oder names_sep()um die Daten bei Bedarf weiter anzupassen."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#praktisches-beispiel",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#praktisches-beispiel",
    "title": "Advanced Dplyr",
    "section": "4 Praktisches Beispiel",
    "text": "4 Praktisches Beispiel\nIm n√§chstes Beipsiel werden wir einen Datensatz umformen, mit dem wir uns im n√§chsten Workshop zu MPT-Modellen besch√§ftigen werden. Der Datensatz enth√§lt f√ºnf Spalten, die die Daten aus einem Priming-Experiment codieren. Insgesamt hat jede Versuchsperson 4 Bedingungen durchlaufen, die in der Spalte stim codiert sind (bg,bp,wg,wp). In jeder dieser Bedingungen mussten die VP eine bin√§re Entscheidungsaufgabe bearbeiten. in den Spalten hits und miss ist codiert, ob die VP die richtige oder falsche Entscheidung getroffen haben. Die Spalte ntrials gibt die Gesamtzahl der Versuche einer Person pro Bedingung an.\n\n\nCode\nhead(freq_dat,5)\n\n\n# A tibble: 5 √ó 5\n# Groups:   subj_idx [2]\n  subj_idx stim   hits ntrials  miss\n     &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;\n1        0 bg       30      31     1\n2        0 bp       28      29     1\n3        0 wg       23      27     4\n4        0 wp       28      33     5\n5        1 bg       28      30     2\n\n\nUm in der Praxis mit dem Datensatz arbeiten zu k√∂nnen, m√ºssen wir diesen jedoch zun√§chst in das richtige Format bringen. Der Datensatz liegt momentan im long-Format vor, f√ºr bestimmte Analysen muss dieser jedoch in das wide-Format umgewandelt werden. Das f√ºhrt dazu, dass es f√ºr jede Bedingung je eine Spalte f√ºr hits und misses geben wird, also z.B. hits_bg und misses_bg.\nNach der Umformung, sieht der Datensatz dann wie folgt aus:\n\n\nCode\n#| echo: true\n#| output: true\n#| warning: false\n#| code-overflow: wrap\n#| collapse: true\n\nhead(freq_dat %&gt;% pivot_wider(names_from = c(\"stim\"),\n                         values_from = c(\"hits\",\"miss\"),\n                         id_cols=\"subj_idx\"),5)\n\n\n# A tibble: 5 √ó 9\n# Groups:   subj_idx [5]\n  subj_idx hits_bg hits_bp hits_wg hits_wp miss_bg miss_bp miss_wg miss_wp\n     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1        0      30      28      23      28       1       1       4       5\n2        1      28      16      27      11       2       2       2       1\n3        3      25      10      33      23       0       0       1       1\n4        4      35      24      27      33       1       0       0       0\n5        5      31      28      25      23       1       2       4       4\n\n\nWas passiert hier genau ? Schritt f√ºr Schritt:\n\nnames_from = c(stim) - Die neuen Spalten sollen aus der Spalte stim benannt werden - (bg,bp,wp,wg)\nvalues_from = c(\"hits\",\"miss\") - in den neuen Spalten sollen die Werte der Hits und Miss Spalten stehen - durch den ersten und zweiten Schritt entstehen also Spalten, die jeweils hits_bg etc. enthalten. Also die Hits aus der Bedingung ‚Äúbg‚Äù usw.\nid_cols - dies soll f√ºr jedes Subject einzeln geschehen."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#√ºbungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R_SS23.html#√ºbungen",
    "title": "Advanced Dplyr",
    "section": "5 √úbungen",
    "text": "5 √úbungen\n\n5.1 case_when()\n1.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúNote_Kategorie‚Äù zu erstellen, die ‚ÄúSehr gut‚Äù f√ºr Noten √ºber 90, ‚ÄúGut‚Äù f√ºr Noten zwischen 80 und 90 und ‚ÄúSchlecht‚Äù f√ºr Noten unter 80 angibt.\n\n\nCode\ndf &lt;- data.frame(Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\n# Your Code Here\n\n\n2.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúBestanden‚Äù zu erstellen, um zu Pr√ºfen ob ein Sch√ºler einer bestimmten Schulform eine Pr√ºfung bestanden hat. Die Bestehensgrenzen sind wie folgt.\n-   F√ºr die Hauptschule liegt die Bestehensgrenze bei 50 %\n-   F√ºr die Realschule liegt die Bestehensgrenze bei 60 %\n-   F√ºr das Gymnasium liegt die Bestehensgrenze bei 70 %\nKodieren Sie das bestehen entweder mit ‚ÄúPass‚Äù oder ‚ÄúFail‚Äù.\n\n\nCode\ndf &lt;- data.frame(Note = runif(100,min=0, max=100),\n                 Schulform = sample(c(\"Gymnasium\",\"Realschule\", \"Hauptschule\"),\n                                    size = 100, replace = T))\n# Your Code here\n\n\n3.) Nutzen Sie die Funktion case_when und die dplyr-Library in R, um eine neue Spalte in dem Datensatz ‚Äúdf‚Äù zu erstellen, die die Einkommenskategorie jeder Person basierend auf ihrem Berufsstatus und ihrem Einkommen kategorisiert. Die Einkommenskategorien sollten wie folgt sein:\n\nF√ºr Angestellte mit einem Einkommen von bis zu 50.000: ‚Äúniedrig‚Äù\nF√ºr Angestellte mit einem Einkommen zwischen 50.000 und 75.000: ‚Äúmittel‚Äù\nF√ºr Angestellte mit einem Einkommen √ºber 75.000: ‚Äúhoch‚Äù\nF√ºr Freiberufler mit einem Einkommen von bis zu 60.000: ‚Äúniedrig‚Äù\nF√ºr Freiberufler mit einem Einkommen zwischen 60.000 und 100.000: ‚Äúmittel‚Äù\nF√ºr Freiberufler mit einem Einkommen √ºber 100.000: ‚Äúhoch‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen von bis zu 30.000: ‚Äúniedrig‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen √ºber 30.000: ‚Äúmittel_hoch‚Äù\n\n\n\nCode\ndf &lt;- data.frame(ID = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45),\n                 Berufsstatus = c(\"Angestellter\", \"Freiberufler\", \"Ruhest√§ndler\"),\n                 Einkommen = c(45000, 75000, 32000))\n\n\n# Your Code here\n\n\n\n\n5.2 Pivotting\n1.) Konvertieren Sie die folgenden Datensatz von wide to long. Erstellen Sie aus den Spalten zwei neue Spalten mit den Namen (month und index). Nutzen Sie dazu das Argument names_sep = \"_\". Die Werte sollen in die Spalte ‚ÄúN‚Äù geschrieben werden.\nTip: Sie m√ºssen bei names_to einen Vektor mit den Namen der neuen Spalten angeben.\n\n\nCode\ndf_wide &lt;- data.frame(\n  Jan_sales = c(10, 40, 70),\n  Feb_sales = c(20, 50, 80),\n  Mar_sales = c(30, 60, 90)\n)\n\n# Your Code here\n\n\n2.) Konvertieren Sie die folgendn Datensatz von long in wide.\n\n\nCode\n    df_long &lt;- data.frame(\n      ID = c(\"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\"),\n      month = c(\"Jan\", \"Jan\", \"Jan\", \"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\"),\n      sales = c(10, 40, 70, 20, 50, 80, 30, 60, 90))\n      \n\n    # Your Code Here"
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). Case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#fortgeschrittene-dplyr-funktionen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#fortgeschrittene-dplyr-funktionen",
    "title": "Advanced Dplyr",
    "section": "",
    "text": "Dplyr bietet neben dem berechnen von neuen Variablen und der M√∂glichkeit Datens√§tze effizient zusammenzufassen noch viele weitere Funktionen, die es erm√∂glichen tiefergehende √Ñnderungen an einem Datensatz vorzunehmen. Dazu geh√∂ren bspw. die Funktionen case_when() und pivot_longer() bzw. pivot_wider(). Case_when() kann dazu genutzt werden, Variablen in Abh√§ngigkeit von bestimmten Bedingungen umzuformen und wird in der Regel zusammen mit mutate() verwendet. pivot_longer() bzw. pivot_wider() wird dazu genutzt einen breiten (wide) Datensatz in einen langen (long) Datensatz umzuwandeln oder umgekehrt."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#case_when---if-else-verkn√ºpf√ºngen-f√ºr-multiple-bedingungen",
    "title": "Advanced Dplyr",
    "section": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen",
    "text": "2 case_when() - if-else Verkn√ºpf√ºngen f√ºr multiple Bedingungen\nDie case_when Funktion in dplyr erm√∂glicht es, basierend auf bestimmten Bedingungen verschiedene Werte f√ºr eine Spalte in einem Datensatz auszuw√§hlen und abh√§ngig vom Variablenwert einen neue Variable zu erstellen. Es ist eine sehr einfache M√∂glichkeit, if-else Statements in eine dplyr-Pipeline zu integrieren.\nDie Syntax eines case_when() Befehles entspricht einer einfachen if oder if-else Verkn√ºpfung. Eine if-else Verkn√ºpfung pr√ºft eine Bedingung und f√ºhrt wenn diese Erf√ºllt ist einen definierten Befehl aus. Ist die Bedingung nicht erf√ºllt, wird andernfalls (else) ein anderer Befehl ausgef√ºhrt:\n\n\n# Vektor von Zahlen darauf testen, ob sie gerade oder ungerade sind:\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei geteilt keinen Rest hat, dann schreibe Gerade, ansonsten Ungerade.\n\nifelse(zahlen %% 2 == 0,\"Gerade\",\"Ungerade\")\n\ncase_when() funktioniert nach der Gleichen Logik:\n\n\n\nDabei wird immer zuerst die if-Bedinungen und deren Output definiert und anschlie√üend mit TRUE die else Bedingung, welche angibt was passiert wenn die if - Bedingung nicht zutrifft:\n\n\n\nzahlen &lt;- c(seq(1:10))\n\n# Wenn die aktuelle Zahl des Vektors durch zwei\n# geteilt keinen Rest hat, dann schreibe Gerade, \n# ansonsten Ungerade.\n\ncase_when(zahlen %% 2 == 0 ~ \"Gerade\",\n          TRUE ~\"Ungerade\")\n\nDer Unterschied von case_when() und ifelse() ist, dass mit case_when() auch mehrere Bedingungen definiert werden k√∂nnen (z.B. wenn eine Variable in mehrere Kategorien eingeteilt werden soll):\n\nHier gibt es auch ein finales else Statement, dieses muss aber nicht sein, solange die Kategorien alle F√§lle abdecken!\n\n2.0.1 case_when: Beispiele\nDas folgende ist ein einfaches Beispiel, bei dem case_when() verwendet wird, um in einem Datensatz eine neue Spalte Alter_Kategorie anhand des Werts in der Spalte Alter zu kategorisieren. Wenn eine neue Spalte erstellt werden soll, muss case_when() immer mit mutate() kombiniert werden:\n\n# Beispiel Datensatz erstellen\ndf &lt;- data.frame(Name = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45))\nhead(df)\n\n# mutate und case_when verwenden, um neue Variable in Abh√§ngigkeit vom Alter zu erstellen:\ndf %&gt;% \n  mutate(Alter_Kategorie = case_when(\n    Alter &lt;= 25 ~ \"jung\",\n    Alter &gt; 25 & Alter &lt;= 35 ~ \"mittel\",\n    Alter &gt; 35 ~ \"alt\"\n  ))\n\nEin weiteres Beispiel haben wir letzte Woche bei der MPT-Modellierung der Daten von Frenken et al.¬†gesehen. Im Datensatz ist shoot als 0 und not shoot als 1 kodiert. F√ºr die MPT Modellierung ben√∂tigen wir aber f√ºr jede Kategorie (Black / Gun, Black / Phone, White / Gun, White / Phone) die Hits und Misses, also die Fehlerraten. Der Datensatz hat praktischerweise eine Spalte, die genau kodiert, was die VP gesehen hat:\n\n\nhead(Study_2_dm)\n\n# A tibble: 6 √ó 6\n  subj_idx stimulus stim     rt response condition\n     &lt;dbl&gt; &lt;fct&gt;    &lt;chr&gt; &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;    \n1        0 gun      bg    0.506        0 black    \n2        0 phone    wp    0.437        0 white    \n3        0 phone    wp    0.483        0 white    \n4        0 phone    bp    0.594        1 black    \n5        0 phone    wp    0.552        1 white    \n6        0 gun      wg    0.417        1 white    \n\n\nIn der zweiten Spalte stimulus ist angebenen, welches Objekt der jeweils zusammen mit der Hautfarbe gezeigt wurde. Da wir wissen, dass nur bei ‚Äúgun‚Äù geschossen werden darf, k√∂nnen wir nun in Kombination mit response (0 - shoot, 1 - not shoot) die Hits mit case_when() in einer neuen Spalte ACC kodieren.\nDazu Verkn√ºpfen wir hier zwei Bedingungen mit dem & Operator. Die erste Bedingung bezieht sich auf die Spalte stimulus, hier muss gepr√ºft werden, welcher Stimulus gezeigt wurde (Gun vs.¬†Phone). Die zweite Bedingung bezieht sich auf die Spalte response. Hier muss gepr√ºft werden, ob geschossen wurde oder nicht. Ingesamt m√ºssen also vier Bedinungen definiert werden, f√ºr jede Kombination von Objekt und Response:\n\nAccuracy in Abh√§ngigkeit von Gegebener Response und Stimulus\n\n\nStimulus\nResponse\nAccuracy\n\n\n\n\nGun\n0\n1\n\n\nGun\n1\n0\n\n\nPhone\n0\n0\n\n\nPhone\n1\n1\n\n\n\nDies m√ºssen wir nun in ein case_when() Befehl √ºbernehmen\n\nMit mutate() die neue Outputspalte benennen\nInnerhalb von mutate() mit case_when() die Accuracy in Abh√§ngigkeit der Spalten Stimulus und Response umkodieren:\n\n\n\nfreq_dat &lt;- Study_2_dm %&gt;% mutate(ACC = case_when(stimulus == \"gun\" & response == 0 ~ 1,\n                                                  stimulus == \"gun\" & response == 1 ~ 0,\n                                                  stimulus == \"phone\" & response == 1 ~ 1,\n                                                  stimulus ==\"phone\" & response == 0 ~ 0))\n\nAnschlie√üend m√ºssen wir nun die Hits und Misses ausz√§hlen. Generell eignen sich zum Ausz√§hlen von bestimmten Bedingungskombinationen oder Trials die Funktionen group_by(), summarise() und n(). n() ist eine einfache Z√§hlfunktion, welche innerhalb von group_by() %&gt;% summarise() dazu f√ºhrt, dass die alle Beobachtungen der gruppierten Variablen (z.B. Subject & Bedingung) innerhalb von summarise() gez√§hlt werden.\nAlso zum Beispiel, wieviele Beobachtung von Subject 1 gibt es in Bedingung A, B und C. Dies macht aber nur Sinn, wenn ihr Daten auf Trial-Ebene (also f√ºr jede Versuchsperson alle Antworten √ºber das ganez Experiment) vorliegen habt. Dies ist hier der Fall, da f√ºr jede Person und jede Bedingung, die diese Person durchlaufen hat, die gegebenen Antworten im Datensatz in der Spalte responses vorliegen.\n\n\nfreq_dat &lt;- freq_dat %&gt;% group_by(subj_idx,stim) %&gt;% \n  summarise(hits = sum(ACC), \n            ntrials=n(), \n            miss=ntrials-hits)\n\n`summarise()` has grouped output by 'subj_idx'. You can override using the\n`.groups` argument.\n\nhead(freq_dat)\n\n# A tibble: 6 √ó 5\n# Groups:   subj_idx [2]\n  subj_idx stim   hits ntrials  miss\n     &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;int&gt; &lt;dbl&gt;\n1        0 bg       30      31     1\n2        0 bp       28      29     1\n3        0 wg       23      27     4\n4        0 wp       28      33     5\n5        1 bg       28      30     2\n6        1 bp       16      18     2\n\n\nWas passiert hier genau ? Schritt f√ºr Schritt:\n\ngroup_by(subj_idx, stim) : Wir gruppieren zun√§chst nach Subject und Bedingung\n\nsummarise(...\n\nhits = sum(ACC) - Wir haben alle Hits mit case_when als 1 kodiert, also k√∂nnen wir die Hits einfach berechnen, indem wir diese aufsummieren.\nnTrials = n() - Ausz√§hlen wieviele Responses ein Subject in jeder stimulus Bedinungen gegeben hat (Gesamtanzahl von gegebenen Antworten in einer Bedingungen pro Person\nmiss = ntrials - hits Alles was kein Hit ist muss ein Miss sein ! Daher k√∂nnen wir einfach die Hits von der Gesamtzahl der Antworten abziehen und erhalten die Anzahl der Misses in jeder Bedinung pro Subject !"
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#long--und-wide-datenformat---datentransformation-in-dplyr",
    "title": "Advanced Dplyr",
    "section": "3 Long- und Wide-Datenformat - Datentransformation in dplyr",
    "text": "3 Long- und Wide-Datenformat - Datentransformation in dplyr\nNun haben wir die Daten von Frenken et al.¬†neu kodiert und die n√∂tigen Informationen im Datensatz, um mit MPTinR zu arbeiten. Allerdings liegen die Daten noch im sogenannten long - Format vor. Oftmals ist es jedoch notwendig, Daten entweder von einem long in ein wide Format oder umgekehrt zu transfomieren. Im Kontext von Datenanalyse und statistischer Modellierung gibt es in der Regel zwei Haupttypen von Datenformaten: wide-Format (breit-Format) und long-Format (lang-Format).\n\n3.1 Wide-Format\n\nIn einem wide Format sind die verschiedenen Merkmale einer einzigen Beobachtung in separaten Spalten dargestellt.\nEine einzige Zeile in einem breiten Datensatz repr√§sentiert eine Beobachtung.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, w√§re in einem breiten Format dargestellt, wobei jede Spalte einem bestimmten Fach entspricht.\nVorteil: Es ist einfach, schnelle √úbersichten √ºber gro√üe Datenmengen zu erhalten.\n\nBeispiel:\n\nwide_df &lt;- data.frame(Sch√ºler_ID = c(1, 2, 3), \n                      Mathe = c(89, 76, 92), \n                      Englisch = c(92, 88, 95), \n                      Wissenschaft = c(88, 72, 98))\nwide_df\n##   Sch√ºler_ID Mathe Englisch Wissenschaft\n## 1          1    89       92           88\n## 2          2    76       88           72\n## 3          3    92       95           98\n\n\n\n3.2 Long-Format\n\nIm long Format sind alle Merkmale einer einzigen Beobachtung in einer Zeile dargestellt.\nEine einzige Spalte in einem long Datensatz repr√§sentiert ein bestimmtes Merkmal.\nBeispiel: Ein Datensatz, der Informationen √ºber die Leistung von Sch√ºlern in verschiedenen F√§chern (Mathematik, Englisch, Wissenschaft) enth√§lt, k√∂nnte in einem langen Format dargestellt werden, wobei jede Zeile einer bestimmten Sch√ºler-Fach-Kombination entspricht.\nVorteil: Es ist einfach, bestimmte Merkmale f√ºr verschiedene Beobachtungen zu vergleichen oder zu analysieren. Au√üerdem ist es f√ºr manche statistische Methoden, wie lineare Regression oder einer ANOVA, das bevorzugte Format.\n\nBeispiel:\n\nlong_df &lt;- data.frame(Sch√ºler_ID = c(rep(1, 3), rep(2, 3), rep(3, 3)), \n                      Fach = c(rep(\"Mathe\", 3), rep(\"Englisch\", 3), rep(\"Wissenschaft\", 3)), \n                      Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\nlong_df\n##   Sch√ºler_ID         Fach Note\n## 1          1        Mathe   89\n## 2          1        Mathe   92\n## 3          1        Mathe   88\n## 4          2     Englisch   76\n## 5          2     Englisch   88\n## 6          2     Englisch   72\n## 7          3 Wissenschaft   92\n## 8          3 Wissenschaft   95\n## 9          3 Wissenschaft   98\n\nEs ist wichtig, das Konzept des wide- und long-Formats zu verstehen, da es bei der Datenaufbereitung und Analyse eine wichtige Rolle spielt. Zum Beispiel kann ein wide -Datensatz schwer zu analysieren sein, wenn man Vergleiche zwischen bestimmten Merkmalen √ºber mehrere Beobachtungen hinweg machen m√∂chte (Beispiel Ergebnisse der Diffusionsmodellierung!). Hier ist es oft besser, den Datensatz in ein long-format zu bringen.\n\n\n3.3 pivot - Funktionen in dplyr\nDie Funktionen pivot_wider und pivot_longer geh√∂ren zu den Funktionen von dplyr und dienen dazu, Datens√§tze zu transformieren.\npivot_wider verwandelt einen long-Format Datensatz in einen wide-Format Datensatz, indem es die Werte einer bestimmten Spalte zu neuen Spalten umbenennt. Dies kann manuell durchgef√ºhrt werden, aber pivot_wider macht dies automatisch und erleichtert so die Datentransformation:\n\n\npivot_longer verwandelt einen wide-Format Datensatz in einen long-Format Datensatz, indem es die Spalten mit bestimmten Werten in einer neuen Spalte zusammenfasst.\nEin Beispiel f√ºr den Einsatz von pivot_wider:\n\n# long data example\nlong_data &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\", \"John\", \"Jane\", \"Jim\"),\n  subject = c(\"physics\", \"physics\", \"physics\", \"math\", \"math\", \"math\"),\n  score = c(85, 90, 80, 75, 80, 70)\n)\n\nlong_data\n## # A tibble: 6 √ó 3\n##   name  subject score\n##   &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n## 1 John  physics    85\n## 2 Jane  physics    90\n## 3 Jim   physics    80\n## 4 John  math       75\n## 5 Jane  math       80\n## 6 Jim   math       70\n\n\n# pivot to wide format\npivot_wider(long_data, names_from = subject, values_from = score)\n## # A tibble: 3 √ó 3\n##   name  physics  math\n##   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n## 1 John       85    75\n## 2 Jane       90    80\n## 3 Jim        80    70\n\nEin Beispiel f√ºr den Einsatz von pivot_longer:\n\n# wide data example\nwide_df &lt;- tibble(\n  name = c(\"John\", \"Jane\", \"Jim\"),\n  Mathe_Note = c(85, 90, 80),\n  Englisch_Note = c(75, 80, 70)\n)\n\n\nwide_df\n## # A tibble: 3 √ó 3\n##   name  Mathe_Note Englisch_Note\n##   &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n## 1 John          85            75\n## 2 Jane          90            80\n## 3 Jim           80            70\n\n\n# pivot to long format\npivot_longer(wide_df, cols = c(Mathe_Note, Englisch_Note), \n             names_to = \"Sch√ºler\", values_to = \"Note\")\n## # A tibble: 6 √ó 3\n##   name  Sch√ºler        Note\n##   &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt;\n## 1 John  Mathe_Note       85\n## 2 John  Englisch_Note    75\n## 3 Jane  Mathe_Note       90\n## 4 Jane  Englisch_Note    80\n## 5 Jim   Mathe_Note       80\n## 6 Jim   Englisch_Note    70\n\n\n\n3.4 Argumente f√ºr pivot_longer und pivot_wider\npivot_longer ben√∂tigt mindestens zwei Argumente:\n\ncols: Dies ist ein Zeichenvektor, der angibt, welche Spalten im Datensatz zusammengefasst werden sollen. -Sch√ºler_ID bedeutet zum Beispiel, dass alle Spalten au√üer Sch√ºler_ID zusammengefasst werden sollen.\nnames_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die zusammengefassten Werte gespeichert werden.\nvalues_to: Dies ist ein Zeichenvektor, der den Namen der neuen Spalte angibt, in der die Werte gespeichert werden, die aus den zusammengefassten Spalten stammen.\n\n\npivot_wider ben√∂tigt mindestens zwei Argumente:\n\nnames_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Namen f√ºr die neuen Spalten verwendet werden soll.\nvalues_from: Dies ist ein Zeichenvektor, der angibt, welche Spalte als Werte f√ºr die neuen Spalten verwendet werden soll.\n\n\nBeide Funktionen haben auch weitere optionale Argumente wie values_fill und names_prefix oder names_sep()um die Daten bei Bedarf weiter anzupassen.\nHier nun die Umformung der Daten von Frenken et al., welche wir vom long Format in das wide Format bringen m√ºssen:\n\n\n#| echo: true\n#| output: true\n#| warning: false\n#| code-overflow: wrap\n#| collapse: true\n\nfreq_dat %&gt;% pivot_wider(names_from = c(\"stim\"),\n                         values_from = c(\"hits\",\"miss\"),\n                         id_cols=\"subj_idx\")\n\n# A tibble: 137 √ó 9\n# Groups:   subj_idx [137]\n   subj_idx hits_bg hits_bp hits_wg hits_wp miss_bg miss_bp miss_wg miss_wp\n      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1        0      30      28      23      28       1       1       4       5\n 2        1      28      16      27      11       2       2       2       1\n 3        3      25      10      33      23       0       0       1       1\n 4        4      35      24      27      33       1       0       0       0\n 5        5      31      28      25      23       1       2       4       4\n 6        6      34      26      18      31       0       0       5       0\n 7        7      29      24      21      36       2       0       1       1\n 8        8      22      29      25      28       0       2      10       2\n 9        9      28      23      22      22       2       0       2       1\n10       10      26      35      25      24       4       0       0       3\n# ‚Ñπ 127 more rows\n\n\nWas passiert hier genau ? Schritt f√ºr Schritt:\n\nnames_from = c(stim) - Die neuen Spalten sollen aus der Spalte stim benannt werden - (bg,bp,wp,wg)\nvalues_from = c(\"hits\",\"miss\") - in den neuen Spalten sollen die Werte der Hits und Miss Spalten stehen - durch den ersten und zweiten Schritt entstehen also Spalten, die jeweils hits_bg etc. enthalten. Also die Hits aus der Bedingung ‚Äúbg‚Äù usw.\nid_cols - dies soll f√ºr jedes Subject einzeln geschehen."
  },
  {
    "objectID": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#√ºbungen",
    "href": "scripts/cogmod/R-Scripts/Advanced R/Advanced_R.html#√ºbungen",
    "title": "Advanced Dplyr",
    "section": "4 √úbungen",
    "text": "4 √úbungen\n\n4.1 case_when\n1.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúNote_Kategorie‚Äù zu erstellen, die ‚ÄúSehr gut‚Äù f√ºr Noten √ºber 90, ‚ÄúGut‚Äù f√ºr Noten zwischen 80 und 90 und ‚ÄúSchlecht‚Äù f√ºr Noten unter 80 angibt.\n\ndf &lt;- data.frame(Note = c(89, 92, 88, 76, 88, 72, 92, 95, 98))\n\n# Your Code Here\ndf_categorized &lt;- df %&gt;% \n  mutate(Note_Kategorie = case_when(\n    Note &gt;= 90 ~ \"Sehr gut\",\n    Note &gt;= 80 & Note &lt; 90 ~ \"Gut\",\n    Note &lt; 80 ~ \"Schlecht\"\n  ))\n\n2.) Verwenden Sie case_when(), um eine neue Spalte mit der Bezeichnung ‚ÄúBestanden‚Äù zu erstellen, um zu Pr√ºfen ob ein Sch√ºler einer bestimmten Schulform eine Pr√ºfung bestanden hat. Die Bestehensgrenzen sind wie folgt.\n-   F√ºr die Hauptschule liegt die Bestehensgrenze bei 50 %\n-   F√ºr die Realschule liegt die Bestehensgrenze bei 60 %\n-   F√ºr das Gymnasium liegt die Bestehensgrenze bei 70 %\nKodieren Sie das bestehen entweder mit ‚ÄúPass‚Äù oder ‚ÄúFail‚Äù.\n\ndf &lt;- data.frame(Note = runif(100,min=0, max=100),\n                 Schulform = sample(c(\"Gymnasium\",\"Realschule\", \"Hauptschule\"),\n                                    size = 100, replace = T))\n# Your Code here\ndf %&gt;% \n  mutate(Pruefungsergebnis = case_when(\n    Schulform == \"Hauptschule\" & Note &gt;= 50 ~ \"Pass\",\n    Schulform == \"Realschule\" & Note &gt;= 60 ~ \"Pass\",\n    Schulform == \"Gymnasium\" & Note &gt;= 70 ~ \"Pass\",\n    TRUE ~ \"Fail\"\n  ))\n\n3.) Nutzen Sie die Funktion case_when und die dplyr-Library in R, um eine neue Spalte in dem Datensatz ‚Äúdf‚Äù zu erstellen, die die Einkommenskategorie jeder Person basierend auf ihrem Berufsstatus und ihrem Einkommen kategorisiert. Die Einkommenskategorien sollten wie folgt sein:\n\nF√ºr Angestellte mit einem Einkommen von bis zu 50.000: ‚Äúniedrig‚Äù\nF√ºr Angestellte mit einem Einkommen zwischen 50.000 und 75.000: ‚Äúmittel‚Äù\nF√ºr Angestellte mit einem Einkommen √ºber 75.000: ‚Äúhoch‚Äù\nF√ºr Freiberufler mit einem Einkommen von bis zu 60.000: ‚Äúniedrig‚Äù\nF√ºr Freiberufler mit einem Einkommen zwischen 60.000 und 100.000: ‚Äúmittel‚Äù\nF√ºr Freiberufler mit einem Einkommen √ºber 100.000: ‚Äúhoch‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen von bis zu 30.000: ‚Äúniedrig‚Äù\nF√ºr Ruhest√§ndler mit einem Einkommen √ºber 30.000: ‚Äúmittel_hoch‚Äù\n\n\ndf &lt;- data.frame(ID = c(\"Peter\", \"Anna\", \"Max\"),\n                 Alter = c(25, 35, 45),\n                 Berufsstatus = c(\"Angestellter\", \"Freiberufler\", \"Ruhest√§ndler\"),\n                 Einkommen = c(45000, 75000, 32000))\n\ndf %&gt;% \n  mutate(Einkommenskategorie = case_when(\n    Berufsstatus == \"Angestellter\" & Einkommen &lt;= 50000 ~ \"niedrig\",\n    Berufsstatus == \"Angestellter\" & Einkommen &gt; 50000 & Einkommen &lt;= 75000 ~ \"mittel\",\n    Berufsstatus == \"Angestellter\" & Einkommen &gt; 75000 ~ \"hoch\",\n    Berufsstatus == \"Freiberufler\" & Einkommen &lt;= 60000 ~ \"niedrig\",\n    Berufsstatus == \"Freiberufler\" & Einkommen &gt; 60000 & Einkommen &lt;= 100000 ~ \"mittel\",\n    Berufsstatus == \"Freiberufler\" & Einkommen &gt; 100000 ~ \"hoch\",\n    Berufsstatus == \"Ruhest√§ndler\" & Einkommen &lt;= 30000 ~ \"niedrig\",\n    Berufsstatus == \"Ruhest√§ndler\" & Einkommen &gt; 30000 ~ \"mittel_hoch\"\n  ))\n##      ID Alter Berufsstatus Einkommen Einkommenskategorie\n## 1 Peter    25 Angestellter     45000             niedrig\n## 2  Anna    35 Freiberufler     75000              mittel\n## 3   Max    45 Ruhest√§ndler     32000         mittel_hoch\n\n\n\n4.2 Pivotting\n1.) Konvertieren Sie die folgenden Datensatz von wide to long. Erstellen Sie aus den Spalten zwei neue Spalten mit den Namen (month und index). Nutzen Sie dazu das Argument names_sep = \"_\". Die Werte sollen in die Spalte ‚ÄúN‚Äù geschrieben werden.\nTip: Sie m√ºssen bei names_to einen Vektor mit den Namen der neuen Spalten angeben.\n\ndf_wide &lt;- data.frame(\n  Jan_sales = c(10, 40, 70),\n  Feb_sales = c(20, 50, 80),\n  Mar_sales = c(30, 60, 90)\n)\n\n# Your Code here\ndf_long &lt;- df_wide %&gt;% pivot_longer(cols=everything(),names_to = c(\"month\",\"index\"), values_to = \"N\",names_sep = \"_\")\n\n2.) Konvertieren Sie die folgendn Datensatz von long in wide.\n\n    df_long &lt;- data.frame(\n      ID = c(\"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\", \"A1\", \"A2\", \"A3\"),\n      month = c(\"Jan\", \"Jan\", \"Jan\", \"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\"),\n      sales = c(10, 40, 70, 20, 50, 80, 30, 60, 90))\n      \n\n    # Your Code Here\n    df_long %&gt;% pivot_wider(names_from = month, values_from = sales)"
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop_stud.html",
    "href": "scripts/ML Workshop/ML_Workshop_stud.html",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "",
    "text": "Im letzten Seminar haben wir sehr ausf√ºhrlich √ºber Maximum Likelihood Estimation (MLE) gesprochen. Heute werden wir einige √úbungen dazu in R programmieren, um ein besseres Verst√§ndnis f√ºr diese Methode zu entwickeln.\nDas Grundprinzip der Maximum-Likelihood-Sch√§tzung besteht darin, die Parameter einer statistischen Verteilung so zu bestimmen, dass die Wahrscheinlichkeit, die beobachteten Daten gegeben bestimmter Parameterwerte, maximiert wird. Gegeben eine Verteilungsfunktion \\(f(x;\\theta)\\), wobei \\(x\\) die beobachteten Daten und \\(\\theta\\) die unbekannten Parameter sind, wird die Likelihood-Funktion definiert als \\[L(\\theta|x)=\\prod_{i=1}^{n} f(x_i;\\theta)\\], wobei \\(n\\) die Anzahl der Datenpunkte ist.\nDas Maximum-Likelihood-Sch√§tzverfahren besteht darin, die Werte von \\(\\theta\\) zu finden, die die Likelihood-Funktion maximieren. Dies kann durch Maximierung des Logarithmus der Likelihood-Funktion mathematisch vereinfacht werden, daher wird oftmals die Log-Likelihood Funktion maximiert und anstelle des Produktes, die Summe √ºber alle Funktionswerte gebildet:\n\\[\\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log f(x_i;\\theta)\\]\n\n\nNehmen wir an, wir haben an einer Sttichprobe die Intelligenz·∫Éerte erhoben und m√∂chten nun den Mittelwert des IQs anhand der Daten mit MLE sch√§tzen. Hierzu brauchen wir zun√§chst eine Dichtefunktion, √ºber die wir die Likelihood berechnen k√∂nnen. Da der IQ in der Population normalverteilt ist k√∂nnen wir hierf√ºr die Normaverteilung heranziehen um eine Likelihoodfunktion zu definieren:\n\\[f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]\nalso ist die Likelihoodfunktion gegeben als\n\\[L(\\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}\n\\] bzw. vereinfacht sich zu folgender Formel, wenn wir den Logarhitmus nehmen:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]"
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop_stud.html#einf√ºhrung",
    "href": "scripts/ML Workshop/ML_Workshop_stud.html#einf√ºhrung",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "",
    "text": "Im letzten Seminar haben wir sehr ausf√ºhrlich √ºber Maximum Likelihood Estimation (MLE) gesprochen. Heute werden wir einige √úbungen dazu in R programmieren, um ein besseres Verst√§ndnis f√ºr diese Methode zu entwickeln.\nDas Grundprinzip der Maximum-Likelihood-Sch√§tzung besteht darin, die Parameter einer statistischen Verteilung so zu bestimmen, dass die Wahrscheinlichkeit, die beobachteten Daten gegeben bestimmter Parameterwerte, maximiert wird. Gegeben eine Verteilungsfunktion \\(f(x;\\theta)\\), wobei \\(x\\) die beobachteten Daten und \\(\\theta\\) die unbekannten Parameter sind, wird die Likelihood-Funktion definiert als \\[L(\\theta|x)=\\prod_{i=1}^{n} f(x_i;\\theta)\\], wobei \\(n\\) die Anzahl der Datenpunkte ist.\nDas Maximum-Likelihood-Sch√§tzverfahren besteht darin, die Werte von \\(\\theta\\) zu finden, die die Likelihood-Funktion maximieren. Dies kann durch Maximierung des Logarithmus der Likelihood-Funktion mathematisch vereinfacht werden, daher wird oftmals die Log-Likelihood Funktion maximiert und anstelle des Produktes, die Summe √ºber alle Funktionswerte gebildet:\n\\[\\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log f(x_i;\\theta)\\]\n\n\nNehmen wir an, wir haben an einer Sttichprobe die Intelligenz·∫Éerte erhoben und m√∂chten nun den Mittelwert des IQs anhand der Daten mit MLE sch√§tzen. Hierzu brauchen wir zun√§chst eine Dichtefunktion, √ºber die wir die Likelihood berechnen k√∂nnen. Da der IQ in der Population normalverteilt ist k√∂nnen wir hierf√ºr die Normaverteilung heranziehen um eine Likelihoodfunktion zu definieren:\n\\[f(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\]\nalso ist die Likelihoodfunktion gegeben als\n\\[L(\\mu, \\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i-\\mu)^2}{2\\sigma^2}}\n\\] bzw. vereinfacht sich zu folgender Formel, wenn wir den Logarhitmus nehmen:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]"
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop_stud.html#mle-in-r",
    "href": "scripts/ML Workshop/ML_Workshop_stud.html#mle-in-r",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "2 MLE in R",
    "text": "2 MLE in R\n\n2.1 √úbung 1: MLE by Hand in R\nUm in R mit der Likelihoodfunktion zu arbeiten, m√ºssen wir zun√§chst Daten simulieren. Hierzu benutzen wir die Funktion rnorm(). Bitte nutzt zun√§chste die Hilfefunktion, um mit rnorm() eine Stichproben von 10000 Werten zu genieren (N = 100), mit dem Mittelwert \\(100\\) und einer Standardabweichung von \\(15\\). Speichert den Output in der Variable ‚Äúiq‚Äù ab. Berechnet f√ºr die gezogene Stichprobe separat Mittelwert und Standardabweichung\n\n\nCode\nset.seed(666)\n# Stichprobe von Werten generieren\n# YOUR CODE HERE....\n\n# Mittelwert und Standardabweichung berechnen\n\n# YOUR CODE HERE....\n# YOUR CODE HERE....\n\n\nZun√§chst wollen wir versuchen, die Likelihoodfunktion in R Code zu √ºbertragen. Nehmt hierzu die Gleichung der Log-Likelihoodfunktion, die wir weiter oben definiert haben:\n\\[ \\ln[L(\\mu,\\sigma)] =  -\\frac{n}{2} \\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (x_i - \\mu)^2\\]\nund dr√ºckt sie in R-Code aus. Ihr ben√∂tigt dazu folgende mathematischen Funktionen:\n\n\n\nFunktion\nCode\n\n\n\n\nSumme Bilden\nsum()\n\n\nQuadrieren\nx^2\n\n\nLogarhitmus\nlog()\n\n\n\\(\\pi\\)\nPi\n\n\nn\nStichprobengr√∂√üe (hier: 100)\n\n\n\nDefiniert zun√§chst zwei Variablen f√ºr unterschiedliche Parametervorschl√§ge f√ºr den Mittelwert von \\(100\\) (=low_iq) und \\(120\\) (high_iq),die Standardabweichung (=sigma) ist f√ºr beide Samples gleich (\\(\\sigma\\) = 15). Als Daten nutzen wir die generierten IQ Werte iq_low und iq_high. In der Gleichung sind \\(x\\) die Daten, also die IQ-Werte aus unserem iq Vektor, \\(\\sigma\\) ist die Standardabweichung und \\(\\mu\\) die unterschiedlichen Vorschl√§ge f√ºr die Mittelwerte, als entweder high_iq oder low_iq. Stellt nun die Gleichung f√ºr beide Parametervorschl√§ge (high vs.¬†low) in R auf. Speichert die Ergebnisse unter den Variablen ll_low und ll_high ab.\n\n\nCode\n# Define sigma and mu\n# high_iq &lt;- # YOUR CODE HERE....\n\n# low_iq &lt;- # YOUR CODE HERE....\n\n# N &lt;- # YOUR CODE HERE....\n# sigma &lt;- # YOUR CODE HERE....\n\n# Define LL-Equation\n\n# ll_low &lt;- # YOUR CODE HERE....\n\n# ll_high &lt;- # YOUR CODE HERE....\n\n\nIhr habt nun f√ºr beide Parametervorschl√§ge, also einmal f√ºr einen Mittelwert von 100 und einmal von einem Mittelwert von 120, die log-likelihood f√ºr die vorliegenden Daten berechnet. Welcher Mittelwert ist nach dieser Likelihood unter den gegebenen Daten wahrscheinlicher ?\n\n\n2.2 Exkurs: Funktionen in R\nFunktionen sind in der Programmierung wichtige Bausteine, um Code wiederverwendbar zu machen und komplexe Aufgaben zu strukturieren. Eine nimmt in der Regel Eingabewerte (Argumente) entgegen, f√ºhrt Operationen oder Berechnungen durch und gibt ein Ergebnis zur√ºck. In R k√∂nnen Funktionen mit dem Schl√ºsselwort function definiert werden. Die Syntax besteht aus dem Funktionsnamen, den Eingabe-Parametern in Klammern, den auszuf√ºhrenden Anweisungen innerhalb des Funktionsk√∂rpers und dem R√ºckgabewert mit return(). Funktionen in R k√∂nnen dann mit den angegebenen Argumenten aufgerufen werden, um den gew√ºnschten Code auszuf√ºhren. Die Verwendung von Funktionen erleichtert das Schreiben, Lesen und Verstehen von Code, da Aufgaben in kleine, wiederverwendbare Einheiten aufgeteilt werden k√∂nnen.\nHier ein einfaches Beispiel einer Funktion, die die Quadratzahl des Inputarguments ausgibt:\n\n\nCode\n# Funktion zur Berechnung der Quadratzahl\nsquare &lt;- function(x) {\n  result &lt;- x^2\n  return(result)\n}\n\n# Verwendung der Funktion\nnum &lt;- 5\nsquared_num &lt;- square(num)\nprint(squared_num)\n\n\n[1] 25\n\n\nInnerhalb einer Funktion in R kann auf die Input-Argumente zugegriffen werden, indem man ihre Namen verwendet. Die Input-Argumente werden in der Funktion als Parameter definiert. Du kannst diese Parameter dann innerhalb der Funktion verwenden, um auf die √ºbergebenen Werte zuzugreifen und damit Berechnungen oder Operationen durchzuf√ºhren.\nZum Beispiel, wenn wir eine Funktion addition() definieren m√∂chten, die zwei Zahlen addiert, k√∂nnten wir die Input-Argumente a und b verwenden:\n\n\nCode\naddition &lt;- function(a, b) {\n  sum &lt;- a + b\n  return(sum)\n}\n\naddition(2,2)\n\n\n[1] 4\n\n\n\n\n2.3 √úbung 2: MLE Using optim()\n\nDiskrepanzfunktion definieren\nNun haben wir im Prinzip ‚Äúby Hand‚Äù eine MLE Sch√§tzung durchgef√ºhrt - zwar nicht iterativ, denn haben wir haben nur zwei m√∂gliche Parameterwerte im Lichte der gegebenen Daten nach der MLE bewertet! R bietet aber auch die M√∂glichkeit, mit der Funktion optim(), eine SIMPLEX Optimierung nach einer gegebenen Diskrepanzfunktion durchzuf√ºhren. Dazu m√ºssen wir der Funktion allerdings eine Funktion √ºbergeben.\nUm nun die optim() zu nutzen im iterativ Parameter nach MLE zu sch√§tzen und durch simplex zu minimieren, m√ºssen wir die gleiche log-likelihood Funktion von √úbung 1 in eine Funktion √ºberf√ºhren. Das ist ganz einfach, denn wir k√∂nnen uns nun, da wir das Grundprinzip von MLE verstanden haben, das Leben mit der in R verf√ºgbaren dnorm() Funktion erleichtern. Diese berechnet ebenfalls die Wahrscheinlichkeit (genauer die Dichte) f√ºr Datenpunkte, gegeben bestimmter Parameter:\n\n\nCode\n# Unsere Gleichung\n# ll_low &lt;- -100/2 * log(2*pi*sigma^2) - 1/(2*sigma^2) * sum((iq - low_iq)^2) \n# print(ll_low)\n# # dnorm() aus R\n# ll_dnorm &lt;- sum(dnorm(x = iq,mean=low_iq,sd=sigma,log = T))\n# print(ll_dnorm)\n\n\nEure Aufgabe ist es nun, eine Funktion zu definieren, die sie aufsummierte log-likelihood ausgibt, wenn Ihr Parameterwerte eingebt. Dazu nutzt ihr die folgende Funktionen aus R:\n\n\n\nFunktion\nCode\n\n\n\n\nSumme Bilden\nsum()\n\n\nLikelihood\ndnorm(daten,mean=,sd=, log=TRUE)\n\n\nLogarhitmus\nlog()\n\n\n\nDie Funktion soll folgende Input-Argumente besitzen:\n\nEinen Vektor Daten (unsere IQ Daten sind ein Vektor)\nEinen Vektor theta, der nur zwei Eintr√§ge enth√§lt - theta¬†ist der Argumentname, um innerhalb der Funktion auf den Input zuzugreifen. Was ihr letztendlich der Funktion als theta √ºbergebt, muss nicht theta hei√üen !\n\nWeiterhin soll diese Funktion die aufsummierte log-Likelihood ausgeben. Definiert diese Funktion unter dem Namen MLE. Die Inputargumente m√ºssen wie im oberen Beispiel einer einfachen Funktion nur mit Namen definiert werden, nicht mit Datentyp. Diesen habe ich nur zum Verst√§ndnis mit angegeben.\n2.) M√ºssen folgende Operationen innerhalb der Funktion ausgef√ºhrt werden\n\nBerechnung der Likelihood unter der verwendung von dnorm(). b.) Aufsummierung der berechneten Likelihood mit sum()\nBerechnung der Deviance - hierzu muss die aufsummierte Likelihood mal -2\ngenommen werden.\n\nWir k√∂nnen hierbei auf die Berechnung des Logarhitmus verzichten, da dnorm() schon den die log-Likelihood mit ausgibt. Hierzu muss allerdings das Argument log = TRUE gesetzt werden ! Zur Erinnerung, auf bestimmte Elemente eines Vektors greift ihr folgenderma√üen zu (dies ist wichtig zu wissen, da Ihr mit den Inputwerten innerhalb der Funktion arbeiten m√ºsst):\n\n\nCode\n# Vektor Definieren\nvektor &lt;- c(1,2,3)\n\n# Erstes Element\n\nvektor[1]\n\n\n[1] 1\n\n\nCode\n# Zweites Element\n\nvektor[2]\n\n\n[1] 2\n\n\nCode\n# Drittes Element\n\nvektor[3]\n\n\n[1] 3\n\n\n3.) Es muss mit return() das Endprodukt zur√ºckgeben, wie in den beiden einfachen Beispielen vorher !\n\n\nCode\n### YOUR CODE HERE \n\n# MLE &lt;- function(Daten, theta) \n# {\n#   mu &lt;- theta[1]\n#   sigma &lt;- theta[2]\n#   \n#   LL &lt;- -2*(sum(dnorm(Daten,mean=mu,sd=sigma,log = T)))\n#   \n#   return(LL)\n#   \n# }\n# \n# # Test your function with different values for theta\n# theta &lt;- c(80,20)\n# MLE(iq,theta)\n\n\n\n\nOptimieren der Parameter mit optim()\nNun da unsere ML-Diskrepanzfunktion funktioniert, m√ºssen wir diese nat√ºrlich minimieren - dazu k√∂nnen wir die Funktion optim() nutzen, die in R zur Verf√ºgung steht. Mit optim() ist standardm√§√üig der SIMPLEX -Algorithmus eingestellt. Es k√∂nnen aber auch andere Algorhithmen genutzt werden. Es werden der Funktion drei Hauptargumente √ºbergeben:\n\npar - ein Vektor mit den Startwerten der Parametersch√§tzung. Die Startwerte sollten nicht √ºberm√§√üig von den erwarteten Werten abweichen. Sch√§tzt man also einen Mittelwert von IQ Daten, macht es keinen Sinn, den Startwert f√ºr den Mittelwert auf 1 zu setzen, da der ‚Äúwahre Wert‚Äù vermutlich zwischen 75 und 150 liegen wird. Gleiches gilt f√ºr die Standardabweichung.\nfn= - die Diskrepanzfunktion die es zu minimieren gilt. Hier die von uns definierte MLE() Funktion.\nDie Daten - diese √ºbergebt ihr mit dem Namen, den Ihr in eurer Funktion verwendet habt, also hier Daten = iq.\n\nOptimiert nun die definierte Funktion mit optim() und speichert die Ergebnisse im Objekt fit.\n\n\nCode\n# YOUR CODE HERE....\n# fit &lt;- optim() \n\n# fit$par\n# \n# # Biased Fit Example \n# \n# iq_pop &lt;- rnorm(1000,mean=100,sd=15)\n# iq_bias &lt;- sample(iq_pop,25)\n# \n# mean(iq_bias)\n\n# Fitting Sample\n# fit &lt;- optim() # YOUR CODE HERE...."
  },
  {
    "objectID": "scripts/ML Workshop/ML_Workshop_stud.html#fazit",
    "href": "scripts/ML Workshop/ML_Workshop_stud.html#fazit",
    "title": "Hands on Maximum Likelihood Parameter Estimation",
    "section": "3 Fazit",
    "text": "3 Fazit\nIn diesem Tutorial haben wir uns mit der Maximum-Likelihood-Sch√§tzung (MLE) in R besch√§ftigt und die Funktion `optim()` verwendet, um die Sch√§tzung durchzuf√ºhren. Zun√§chst haben wir die Likelihood-Funktion selbst definiert und verschiedene Parameterwerte getestet, um das Konzept der MLE besser zu verstehen.\nDurch die Verwendung von `optim()` konnten wir die MLE iterativ implementieren und die optimalen Parameterwerte finden, die die Likelihood-Funktion maximieren (oder die Deviance minimieren). Wir haben gesehen, dass `optim()` eine effiziente Methode zur numerischen Optimierung ist und verschiedene Algorithmen zur Verf√ºgung stellt.\nDie Maximum-Likelihood-Sch√§tzung ist ein leistungsstarkes Werkzeug, um Parameter in statistischen Modellen zu sch√§tzen. Es erm√∂glicht uns, die Wahrscheinlichkeit der beobachteten Daten unter verschiedenen Annahmen zu maximieren und die besten Parameterwerte zu ermitteln."
  },
  {
    "objectID": "about/about_MLM_sose23.html",
    "href": "about/about_MLM_sose23.html",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Achtung üöß\n\n\n\nDies ist ein ‚Äúlebendiges‚Äù Dokument. Es ist m√∂glich, dass einige Aktuallisierungen und Erg√§nzungen nach dem ersten Seminar-Block vorgenommen werden.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "1. Allgemeine Informationen"
    ]
  },
  {
    "objectID": "about/about_MLM_sose23.html#seminarleitung",
    "href": "about/about_MLM_sose23.html#seminarleitung",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "Seminarleitung",
    "text": "Seminarleitung\nJos√© C. Garc√≠a Alanis\nAbteilung f√ºr Analyse und Modellierung komplexer Daten\nPsychologisches Institut\nJohannes Gutenberg-Universit√§t Mainz Wallstra√üe 3, Raum 06-255\nD-55122 Mainz\njose.alanis at uni-mainz.de",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "1. Allgemeine Informationen"
    ]
  },
  {
    "objectID": "about/about_MLM_sose23.html#organisatorisches-und-wichtige-infos",
    "href": "about/about_MLM_sose23.html#organisatorisches-und-wichtige-infos",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "Organisatorisches und wichtige Infos",
    "text": "Organisatorisches und wichtige Infos\n\nAllgemeine Materialien f√ºr das Seminar\n\nWichtige Informationen und Kursmaterialien werden auf die LMS/Moodle-Seite des Seminars ver√∂ffentlicht:\n\nLink zum Seminar auf LMS.\n\nWann: Montags von 12:15 - 13:45 Uhr (17.04.22 - Mo. 17.07.23).\nWo: Seminarraum 01-211 (kleiner H√∂rsaal) im Psychologischen Institut (Binger Str.)\n\n\n\n\n\nInhalt des Seminars\n\nMulti-Level Modelle haben viele Namen. H√§ufig werden sie Mehrebenen-Modelle, Mixed Effects Models oder Random Coefficient Models genannt. Eine weitere h√§ufige Bezeichnung f√ºr Multi-Level Modelle lautet Hierarchische Lineare Modelle. Dies hat zum Grund, dass Multi-Level Modelle eine statische Methode darstellen, die zur Analyse von hierarchisch strukturierten Daten (auch genestete Daten genannt) eingesetzt werden kann. Was genau versteckt sich hinter dem Begriff ‚Äûhierarchisch strukturierte Daten‚Äú und warum sind Multi-Level Modelle ein n√ºtzliches ‚ÄûTool‚Äú, um Erkenntnisse aus dieser Art von Daten zu gewinnen? Mit diesen Fragen werden wir uns im Laufe des Seminars besch√§ftigen.\n\n\n\nLernziele\n\nIn diesem Seminar werden Sie lernen, wie Sie Multi-Level Modelle zur Analyse von ‚Äûhierarchisch organisierten Daten‚Äú anwenden k√∂nnen. Ziel des Seminars ist es, Sie zu theoretisch-konzeptionellen √úberlegungen zu motivieren und Ihnen die statistisch-methodologischen Grundlagen zu vermitteln, sodass Sie in der Lage sind zu entscheiden, wann ein Multi-Level Modell zu Beschreibung von Zusammenh√§ngen, die √ºberlegene statistische Methode darstellt. Des Weiteren werden Sie Kennwerte und Methoden kennenlernen, die eigensetzt werden k√∂nnen, um die Aussagekraft und (potenziell inkrementelle) Validit√§t eines Multi-Level Modells einzusch√§tzen. Am Ende des Seminars werden Sie im Stande sein, ein eigenes Analyseprojekt durchzuf√ºhren, in dem Multi-Level Modelle zum Einsatz kommen. Diese Fragen werden Sie im Laufe des Seminars bearbeiten:\n\n\n\nWas versteht man unter ‚Äûhierarchisch strukturierten/organisierten Daten‚Äú?\n\nWie k√∂nnen diese erkannt werden?\nWelche Konsequenzen (im Sinne statistisch-methodologischer Einschr√§nkungen) bringen hierarchisch strukturierte Daten mit sich?\nWelche theoretisch-konzeptuelle √úberlegungen m√ºssen ber√ºcksichtigt werden?\n\nWie unterschieden sich Multi-Level Modelle von anderen statistischen Analyseverfahren?\n\nWas sind Gemeinsamkeiten?\n\nWie werden Multi-Level Modelle gesch√§tzt? (Was beschreiben sie?)\n\nWelche Arten von Modellen gibt es?\n\nWie k√∂nnen Multi-Level Modelle in der Programmiersprache R spezifiziert werden?\nWie sind die Ergebnisse eines Multilevel-Modells zu interpretieren?\nWie sind die Ergebnisse eines Multilevel-Modells zu bewerten?\n\nz.B. im Sinne ihrer Aussagekraft, Reliabilit√§t und Validit√§t.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "1. Allgemeine Informationen"
    ]
  },
  {
    "objectID": "about/about_MLM_sose23.html#begleitendes-tutorium",
    "href": "about/about_MLM_sose23.html#begleitendes-tutorium",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "Begleitendes Tutorium",
    "text": "Begleitendes Tutorium\n\nDas Seminar wird von einem Tutorium (Softwarekurs) begleitet. Im Tutorium werden Sie die Grundlagen des Statistiksoftware und Programmiersprache R. Sie werden in dem Umgang mit Daten geschult und werden verschiedene Techniken zur Datenaufbereitung erlernen und ein√ºben. Dieser Teil des Tutoriums findet im ersten Teil des Semesters statt. Sie sollten in eines der beiden Tutorien angemeldet sein, entweder am Montag oder am Mittwoch. Besuchen das Tutorium. Erfahrungsgem√§√ü k√∂nnen viele Fragen und Start-Schwierigkeiten im Umgang mit R im Tutorium gut aufgefangen und gel√∂st werden. Im zweiten Teil des Semesters findet ein vertiefendes Tutorium statt. Dieser baut auf die, Grundkenntnissen, die Sie im ersten Teil des Semersten erlernt haben werden. Im zweiten Teil des Semesters besuchen Sie das Tutorium bei mir. Die Termine f√ºr Tutorium bleiben wie gehabt. Sie m√ºssen das Tutorium nicht wechseln. Bitte bleiben Sie in Ihren Gruppen, ich werde die Veranstaltung von den jeweiligen Kollegen:innen √ºbernehmen und zur gewohnten Zeit anbieten. Wir eine Reihe von Materialien zusammengestellt, um Ihnen den Einstieg in die Programmiersprache R zur erleichtern. Diese k√∂nnen Sie unter dem folgenden Link erreichen:\n\n\n\nR-Kurs-Buch von der Abteilung Analyse und Modellierung komplexer Daten.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "1. Allgemeine Informationen"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression_parameters.html",
    "href": "mlm_seminar_sose23/lineare_regression_parameters.html",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "In den letzten Sitzungen haben wir uns mit der einfachen linearen Regression befasst. Dabei haben wir uns erst einmal daf√ºr entschieden, eine Regression ohne Ber√ºcksichtigung der verschiedenen Subgruppen in den Daten zu berechnen.\nMit einem Pr√§diktor (\\(x_{1}\\) ), lautet die Formel der Regression:\n\\[\n\\widehat{y}_{m} = b_{0} + b_{1} \\cdot x_{m1}\n\\tag{1}\\]\nSie liefert uns zwei Parameter $b_{0} und \\(b_{1}\\).\n\n\\(b_{0} =\\) \\(y\\)-Achsenabschnitt, Konstante, oder Interzept:\n\nDer Wert von \\(y\\) bei einer Auspr√§gung von 0 in \\(x\\).\n\n\\(b_{1} =\\) Regressionsgewicht des Pr√§diktors oder die Steigung der Regressionsgerade.\n\nInterpretation: die Steigung der Geraden l√§sst erkennen, um wie viele Einheiten \\(y\\) zunimmt, wenn \\(x\\) um eine Einheit zunimmt.\n\n\nUm die ‚ÄúInterpretierbarkeit‚Äù der Parameter (vorallem die des Interzepts.\nWir haben ebenfalls √ºber ‚ÄúZentrierung‚Äù gesprochen. Wenn wir eine Variable an ihren Mittelwert zentrieren, ziehen wir den Mittelwert der Variable von allen Werten (d.h. alle Beobachtungen) der Variable ab. Zentrierung definiert das Minimum und Maximum der Variable neu. Der Mittelwert einer am Mittelwert zentrierten Variable ist nun gleich Null. Wir k√∂nnen Zentrierung als eine ‚ÄúDaten-Vorverarbeitungsstrategie‚Äù betrachten, die die ‚ÄúInterpretierbarkeit‚Äù der Parameter (vor allem die des Intercepts) in einem linearen Modell steigert.\nBetrachten wir z.B. die folgende Abbildung:\n\n\n\n\n\n\n\n\n\nDargestellt sind die Ergebnisse zweier Regressionen. Beide Regressionen beschreiben den Zusammenhang zwischen Schulunlust und Schulleistung. Die linke Seite der Abbildung zeigt die Ergebnisse der Regression ohne Zentrierung von Schulunlust und die rechte Seite mit Zentrierung. Ein Unterschied ist, dass die Spannweite der zentrierten Daten ein anderer ist. Personen, die einen negativen Wert in der zeitrierten Schulunlust-Variable haben, befinden sich unterhalb des Mittelwert der Gesamtstichprobe. Personen mit positiven Werten befinden sich dar√ºber. Ein weiterer Unterschied f√§llt auf, wenn wir die Intercepts der Modelle betrachten. Das Interzept auf der rechten Seite liegt inmitten der Verteilung (auf dem Mittelwert, welcher nach Zentrierung gleich Null ist). Zentrierung kann uns also helfen, das Interzept in einem f√ºr uns interpretierbaren Bereich ‚Äúzu holen‚Äù.\n\n\n\nGehen wir nun zu einem Beispiel √ºber, das die Subgruppen in den Daten ber√ºcksichtigt. Daf√ºr ben√∂tigen wir die folgenden Daten:\n\n# die Daten k√∂nnen mit diesem Befehl geladen werden\nurlRemote &lt;- 'https://raw.githubusercontent.com/JoseAlanis/amdstatsem/main'\nfpathData &lt;- '/data/schulunlust.txt'\ndata_schulleistung &lt;- read.table(paste0(urlRemote, fpathData),\n                          header = TRUE, dec = ',')\n\n# wir werden nur die ersten 5 klassen benutzen\n# wir k√∂nnen die Daten dieser Klassen mit\n# `dplyr`filtern\nrequire(dplyr)\ndata_schulleistung &lt;- data_schulleistung %&gt;%\n  filter(klasse_nr &lt;= 5) %&gt;%\n  # ebenfalls werden wir die variable `unlust`\n  # zentrieren\n  mutate(unlust_c = unlust - mean(unlust))\n\nDiese Daten sind identisch mit den Daten der obigen Abbildung.\n\n\n\nErster Schritt:\n\nBerechnen wir erst einmal eine Gesamt-Regression, ohne die Subgruppen (die einzelnen Klassen) in den Daten zu ber√ºcksichtigen.\nZur Erinnerung: Der R-Befehl, um eine lineare Regression zu berechnen lautet lm(fomula, data)\n\nZweiter Schritt:\n\nBerechnen wir 5 verschiedene Regressionen, eine f√ºr jede Klasse.\nTipp: Sie k√∂nnen die Daten der einzelnen Klassen mit dplyr() filtern.\n\nz.B.: klasse_1 &lt;- data_schulleistung %&gt;% filter(klasse_nr == 1)\nDanach k√∂nnen Sie die Regression mit lm() berechnen.\n\n\nSchreiben Sie \\(b_{0}\\) und \\(b_{1}\\) f√ºr alle Regressionen auf und vergleichen Sie.\n\n\n\nDie Ergebnisse sollten mit der folgenden Abbildung kompatibel sein.\n\n\n\n\n\n\n\n\n\n\n\nRegressionsparameter f√ºr das jeweilige \"Klassenmodell\"Modelbeta_0beta_1119.086-0.552219.212-0.266319.310-1.397424.9371.087524.6160.087Note. 1 = Klasse 1; 2 = Klasse 2; etc.\n\n\n\n\n\n\nVergleichen Sie nun die Ergebnisse der einzelnen Regressionen mit den Ergebnissen eines ‚ÄúGesamtregressionsmodells‚Äù (ein Modell √ºber alle Klassen hinweg).\nHier sind die Ergebnisse:\n\nges_mod &lt;- lm(data = data_schulleistung,\n              leistung ~  unlust_c)\n\nges_df &lt;- data.frame(model = 'gesamt',\n                     beta_0 = summary(ges_mod)$coefficients[1],\n                     beta_1 = summary(ges_mod)$coefficients[2])\n\nnice_table(ges_df,\n           col.format.custom = 2:3, format.custom = \"fun\",\n           title = 'Regressionsparameter f√ºr das \"Gesamtmodell\"',\n           width = 0.5)\n\nRegressionsparameter f√ºr das \"Gesamtmodell\"modelbeta_0beta_1gesamt21.053-1.128",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "4. Parametersch√§tzung"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression_parameters.html#bezug-zur-vorherigen-stunde",
    "href": "mlm_seminar_sose23/lineare_regression_parameters.html#bezug-zur-vorherigen-stunde",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "In den letzten Sitzungen haben wir uns mit der einfachen linearen Regression befasst. Dabei haben wir uns erst einmal daf√ºr entschieden, eine Regression ohne Ber√ºcksichtigung der verschiedenen Subgruppen in den Daten zu berechnen.\nMit einem Pr√§diktor (\\(x_{1}\\) ), lautet die Formel der Regression:\n\\[\n\\widehat{y}_{m} = b_{0} + b_{1} \\cdot x_{m1}\n\\tag{1}\\]\nSie liefert uns zwei Parameter $b_{0} und \\(b_{1}\\).\n\n\\(b_{0} =\\) \\(y\\)-Achsenabschnitt, Konstante, oder Interzept:\n\nDer Wert von \\(y\\) bei einer Auspr√§gung von 0 in \\(x\\).\n\n\\(b_{1} =\\) Regressionsgewicht des Pr√§diktors oder die Steigung der Regressionsgerade.\n\nInterpretation: die Steigung der Geraden l√§sst erkennen, um wie viele Einheiten \\(y\\) zunimmt, wenn \\(x\\) um eine Einheit zunimmt.\n\n\nUm die ‚ÄúInterpretierbarkeit‚Äù der Parameter (vorallem die des Interzepts.\nWir haben ebenfalls √ºber ‚ÄúZentrierung‚Äù gesprochen. Wenn wir eine Variable an ihren Mittelwert zentrieren, ziehen wir den Mittelwert der Variable von allen Werten (d.h. alle Beobachtungen) der Variable ab. Zentrierung definiert das Minimum und Maximum der Variable neu. Der Mittelwert einer am Mittelwert zentrierten Variable ist nun gleich Null. Wir k√∂nnen Zentrierung als eine ‚ÄúDaten-Vorverarbeitungsstrategie‚Äù betrachten, die die ‚ÄúInterpretierbarkeit‚Äù der Parameter (vor allem die des Intercepts) in einem linearen Modell steigert.\nBetrachten wir z.B. die folgende Abbildung:\n\n\n\n\n\n\n\n\n\nDargestellt sind die Ergebnisse zweier Regressionen. Beide Regressionen beschreiben den Zusammenhang zwischen Schulunlust und Schulleistung. Die linke Seite der Abbildung zeigt die Ergebnisse der Regression ohne Zentrierung von Schulunlust und die rechte Seite mit Zentrierung. Ein Unterschied ist, dass die Spannweite der zentrierten Daten ein anderer ist. Personen, die einen negativen Wert in der zeitrierten Schulunlust-Variable haben, befinden sich unterhalb des Mittelwert der Gesamtstichprobe. Personen mit positiven Werten befinden sich dar√ºber. Ein weiterer Unterschied f√§llt auf, wenn wir die Intercepts der Modelle betrachten. Das Interzept auf der rechten Seite liegt inmitten der Verteilung (auf dem Mittelwert, welcher nach Zentrierung gleich Null ist). Zentrierung kann uns also helfen, das Interzept in einem f√ºr uns interpretierbaren Bereich ‚Äúzu holen‚Äù.",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "4. Parametersch√§tzung"
    ]
  },
  {
    "objectID": "mlm_seminar_sose23/lineare_regression_parameters.html#ber√ºcksichtigung-von-subgruppen",
    "href": "mlm_seminar_sose23/lineare_regression_parameters.html#ber√ºcksichtigung-von-subgruppen",
    "title": "Seminar Fortgeschrittene statistische Methoden II (1)",
    "section": "",
    "text": "Gehen wir nun zu einem Beispiel √ºber, das die Subgruppen in den Daten ber√ºcksichtigt. Daf√ºr ben√∂tigen wir die folgenden Daten:\n\n# die Daten k√∂nnen mit diesem Befehl geladen werden\nurlRemote &lt;- 'https://raw.githubusercontent.com/JoseAlanis/amdstatsem/main'\nfpathData &lt;- '/data/schulunlust.txt'\ndata_schulleistung &lt;- read.table(paste0(urlRemote, fpathData),\n                          header = TRUE, dec = ',')\n\n# wir werden nur die ersten 5 klassen benutzen\n# wir k√∂nnen die Daten dieser Klassen mit\n# `dplyr`filtern\nrequire(dplyr)\ndata_schulleistung &lt;- data_schulleistung %&gt;%\n  filter(klasse_nr &lt;= 5) %&gt;%\n  # ebenfalls werden wir die variable `unlust`\n  # zentrieren\n  mutate(unlust_c = unlust - mean(unlust))\n\nDiese Daten sind identisch mit den Daten der obigen Abbildung.\n\n\n\nErster Schritt:\n\nBerechnen wir erst einmal eine Gesamt-Regression, ohne die Subgruppen (die einzelnen Klassen) in den Daten zu ber√ºcksichtigen.\nZur Erinnerung: Der R-Befehl, um eine lineare Regression zu berechnen lautet lm(fomula, data)\n\nZweiter Schritt:\n\nBerechnen wir 5 verschiedene Regressionen, eine f√ºr jede Klasse.\nTipp: Sie k√∂nnen die Daten der einzelnen Klassen mit dplyr() filtern.\n\nz.B.: klasse_1 &lt;- data_schulleistung %&gt;% filter(klasse_nr == 1)\nDanach k√∂nnen Sie die Regression mit lm() berechnen.\n\n\nSchreiben Sie \\(b_{0}\\) und \\(b_{1}\\) f√ºr alle Regressionen auf und vergleichen Sie.\n\n\n\nDie Ergebnisse sollten mit der folgenden Abbildung kompatibel sein.\n\n\n\n\n\n\n\n\n\n\n\nRegressionsparameter f√ºr das jeweilige \"Klassenmodell\"Modelbeta_0beta_1119.086-0.552219.212-0.266319.310-1.397424.9371.087524.6160.087Note. 1 = Klasse 1; 2 = Klasse 2; etc.\n\n\n\n\n\n\nVergleichen Sie nun die Ergebnisse der einzelnen Regressionen mit den Ergebnissen eines ‚ÄúGesamtregressionsmodells‚Äù (ein Modell √ºber alle Klassen hinweg).\nHier sind die Ergebnisse:\n\nges_mod &lt;- lm(data = data_schulleistung,\n              leistung ~  unlust_c)\n\nges_df &lt;- data.frame(model = 'gesamt',\n                     beta_0 = summary(ges_mod)$coefficients[1],\n                     beta_1 = summary(ges_mod)$coefficients[2])\n\nnice_table(ges_df,\n           col.format.custom = 2:3, format.custom = \"fun\",\n           title = 'Regressionsparameter f√ºr das \"Gesamtmodell\"',\n           width = 0.5)\n\nRegressionsparameter f√ºr das \"Gesamtmodell\"modelbeta_0beta_1gesamt21.053-1.128",
    "crumbs": [
      "Seminar Multi-Level Modelle",
      "4. Parametersch√§tzung"
    ]
  }
]